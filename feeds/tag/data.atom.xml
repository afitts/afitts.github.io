<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Alex Fitts</title><link href="http://localhost:8000/" rel="alternate"></link><link href="http://localhost:8000/feeds/tag/data.atom.xml" rel="self"></link><id>http://localhost:8000/</id><updated>2015-02-15T00:00:00-06:00</updated><entry><title>Web Scraping 201: finding the API</title><link href="http://localhost:8000/2015/02/15/web-scraping-finding-the-api/" rel="alternate"></link><published>2015-02-15T00:00:00-06:00</published><author><name>Alex Fitts</name></author><id>tag:localhost:8000,2015-02-15:2015/02/15/web-scraping-finding-the-api/</id><summary type="html">&lt;p&gt;Previously, I explained &lt;a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/"&gt;how to scrape a page&lt;/a&gt; where the data is rendered &lt;em&gt;server-side&lt;/em&gt;. However, the increasing popularity of Javascript frameworks such as &lt;a href="https://angularjs.org"&gt;AngularJS&lt;/a&gt; coupled with &lt;a href="http://en.wikipedia.org/wiki/Representational_state_transfer#Applied_to_web_services"&gt;RESTful APIs&lt;/a&gt; means that fewer sites are generated server-side and are instead being rendered &lt;em&gt;client-side&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In this post, I’ll give a brief overview of the differences between the two and show how to find the underlying API, allowing you to get the data you’re looking for.&lt;/p&gt;
&lt;h2&gt;Server-side vs client-side&lt;/h2&gt;
&lt;p&gt;Imagine we have a database of sports statistics and would like to build a web application on top of it (e.g. something like &lt;a href="http://www.basketball-reference.com/"&gt;Basketball Reference&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;If we build our web app using a server-side framework like &lt;a href="https://www.djangoproject.com/"&gt;Django&lt;/a&gt; [1], something akin to the following happens each time a user visits a page.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;User’s browser sends a request to the server hosting our application.&lt;/li&gt;
&lt;li&gt;Our server processes the request, checking to make sure the URL requested exists (amongst other things).&lt;/li&gt;
&lt;li&gt;If the requested URL does not exist, send an error back to the user’s browser and direct them to a &lt;a href="http://en.wikipedia.org/wiki/HTTP_404#Custom_error_pages"&gt;404 page&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;If the requested URL does exist, execute some code &lt;em&gt;on the server&lt;/em&gt; which gets data from our database. Let’s say the user wants to see &lt;a href="http://www.basketball-reference.com/players/w/walljo01/gamelog/2015/"&gt;John Wall’s game-by-game stats&lt;/a&gt; for the 2014-15 NBA season. In this case, our Django/Python code queries the database and receives the data.&lt;/li&gt;
&lt;li&gt;Our Django/Python code injects the data into our application’s &lt;a href="http://en.wikipedia.org/wiki/Web_template_system"&gt;templates&lt;/a&gt; to complete the HTML for the page.&lt;/li&gt;
&lt;li&gt;Finally, the server sends the HTML to the user’s browser (a &lt;em&gt;response&lt;/em&gt; to their &lt;em&gt;request&lt;/em&gt;) and the page is displayed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;To illustrate the last step, go to &lt;a href="http://www.basketball-reference.com/players/w/walljo01/gamelog/2015/"&gt;John Wall’s game log&lt;/a&gt; and &lt;a href="view-source:http://www.basketball-reference.com/players/w/walljo01/gamelog/2015/"&gt;view the page source&lt;/a&gt;. Ctrl+f or Cmd+f and search for “2014-10-29”. This is the first row of the game-by-game stats table. We know the page was created server-side because the data is present in the page source.&lt;/p&gt;
&lt;p&gt;However, if the web application is built with a client-side framework like Angular, the process is slightly different. In this case, the server still sends the static content (the HTML, CSS, and Javascript), but the HTML is only a template - it doesn’t hold any data. Separately, the Javascript in the server response fetches the data from an API and uses it to create the page &lt;em&gt;client-side&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;To illustrate, view the source of &lt;a href="http://stats.nba.com/player/#!/202322/tracking/shotslogs/"&gt;John Wall’s shot log&lt;/a&gt; page on NBA.com - there’s no data to scrape! &lt;a href="view-source:http://stats.nba.com/player/#!/202322/tracking/shotslogs/"&gt;See for yourself&lt;/a&gt;. Ctrl+f or Cmd+f for “Was @“. Despite there being many instances of it in the shot log table, none found in the page source.&lt;/p&gt;
&lt;p&gt;If you’re thinking “Oh crap, I can’t scrape this data,” well, you’re in luck! Applications using an API are often &lt;em&gt;easier&lt;/em&gt; to scrape - you just need to know how to find the API. Which means I should probably tell you how to do that.&lt;/p&gt;
&lt;h2&gt;Finding the API&lt;/h2&gt;
&lt;p&gt;With a client-side app, your browser is doing much of the work. And because your browser is what’s rendering the HTML, we can use it to see where the data is coming from using its built-in developer tools.&lt;/p&gt;
&lt;p&gt;To illustrate, I’ll be using Chrome, but Firefox should be more or less the same (Internet Explorer users … you should switch to Chrome or Firefox and not look back).&lt;/p&gt;
&lt;p&gt;To open Chrome’s Developer Tools, go to View -&amp;gt; Developer -&amp;gt; Developer Tools. In Firefox, it’s Tools -&amp;gt; Web Developer -&amp;gt; Toggle Tools. We’ll be using the Network tab, so click on that one. It should be empty.&lt;/p&gt;
&lt;p&gt;Now, go to the page that has your data. In this case, it’s &lt;a href="http://stats.nba.com/player/#!/202322/tracking/shotslogs/"&gt;John Wall’s shot logs&lt;/a&gt;. If you’re already on the page, hit refresh. Your Network tab should look similar to this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="network tab example" src="/images/scraping-network-tab.png" /&gt;&lt;/p&gt;
&lt;p&gt;Next, click on the XHR filter. XHR is short for &lt;a href="http://en.wikipedia.org/wiki/XMLHttpRequest"&gt;XMLHttpRequest&lt;/a&gt; - this is the type of request used to fetch XML or JSON data. You should see a couple entries in this table (screenshot below). One of them is the API request that returns the data you’re looking for (in this case, John Wall’s shots).&lt;/p&gt;
&lt;p&gt;&lt;img alt="XHR requests example" src="/images/scraping-xhr-tab.png" /&gt;&lt;/p&gt;
&lt;p&gt;At this point, you’ll need to explore a bit to determine which  request is the one you want. For our example, the one starting with “playerdashptshotlog” sounds promising. Let’s click on it and view it in the Preview tab. Things should now look like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="API response preview" src="/images/scraping-api-preview.png" /&gt;&lt;/p&gt;
&lt;p&gt;Bingo! That’s the API endpoint. We can use the Preview tab to explore the response.&lt;/p&gt;
&lt;p&gt;&lt;img alt="API results preview" src="/images/scraping-api-results-preview.png" /&gt;&lt;/p&gt;
&lt;p&gt;You should see a couple of objects:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The resource name - &lt;em&gt;playerdashptshotlog&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;The parameters (you might need to expand the resource section). These are the request parameters that were passed to the API. You can think of them like the &lt;code&gt;WHERE&lt;/code&gt; clause of a SQL query. This request has parameters of &lt;code&gt;Season=2014-15&lt;/code&gt; and &lt;code&gt;PlayerID=202322&lt;/code&gt; (amongst others). Change the parameters in the URL and you’ll get different data (more on that in a bit).&lt;/li&gt;
&lt;li&gt;The result sets. This is self-explanatory.&lt;/li&gt;
&lt;li&gt;Within the result sets, you’ll find the headers and row set. Each object in the row set is essentially the result of a database query, while the headers tell you the column order. We can see that the first item in each row corresponds to the Game_ID, while the second is the Matchup.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now, go to the Headers tab, grab the request URL, and open it in a new browser tab, we’ll see the data we’re looking for (example below). Note that I'm using &lt;a href="https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc?hl=en"&gt;JSONView&lt;/a&gt;, which nicely formats JSON in your browser.&lt;/p&gt;
&lt;p&gt;&lt;img alt="API response" src="/images/scraping-api-response.png" /&gt;&lt;/p&gt;
&lt;p&gt;To grab this data, we can use something like Python’s &lt;a href="http://docs.python-requests.org/en/latest/"&gt;requests&lt;/a&gt;. Here’s an example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;

&lt;span class="n"&gt;shots_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://stats.nba.com/stats/playerdashptshotlog?&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; \
    &lt;span class="s1"&gt;&amp;#39;DateFrom=&amp;amp;DateTo=&amp;amp;GameSegment=&amp;amp;LastNGames=0&amp;amp;LeagueID=00&amp;amp;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; \
    &lt;span class="s1"&gt;&amp;#39;Location=&amp;amp;Month=0&amp;amp;OpponentTeamID=0&amp;amp;Outcome=&amp;amp;Period=0&amp;amp;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; \
    &lt;span class="s1"&gt;&amp;#39;PlayerID=202322&amp;amp;Season=2014-15&amp;amp;SeasonSegment=&amp;amp;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; \
    &lt;span class="s1"&gt;&amp;#39;SeasonType=Regular+Season&amp;amp;TeamID=0&amp;amp;VsConference=&amp;amp;VsDivision=&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;# request the URL and parse the JSON&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shots_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;raise_for_status&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="c1"&gt;# raise exception if invalid response&lt;/span&gt;
&lt;span class="n"&gt;shots&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="p"&gt;()[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;resultSets&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;rowSet&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c1"&gt;# do whatever we want with the shots data&lt;/span&gt;
&lt;span class="n"&gt;do_things&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;shots&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That’s it. Now you have the data and can get to work.&lt;/p&gt;
&lt;p&gt;Note that passing different parameter values to the API yields different results. For instance, change the Season parameter to 2013-14 - now you have John Wall’s shots for the 2013-14 season. Change the PlayerID to 201935 - now you have James Harden’s shots.&lt;/p&gt;
&lt;p&gt;Additionally, different APIs return different types of data. Some might send XML; others, JSON. Some might store the results in an array of arrays; others, an array of maps or dictionaries. Some might not return the column headers at all. Things are vary between sites.&lt;/p&gt;
&lt;p&gt;Had a situation where you haven't been able to find the data you're looking for in the page source? Well, now you know how to find it.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Was there something I missed? Have questions? &lt;a href="https://twitter.com/gjreda"&gt;Let me know&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;hr class=“small”&gt;
[1] Really this can be any server-side framework - Ruby on Rails, PHP’s Drupal or CodeIgniter, etc.&lt;/p&gt;</summary><category term="scraping"></category><category term="python"></category><category term="data"></category><category term="tutorial"></category></entry><entry><title>Scraping Craigslist for sold out concert tickets</title><link href="http://localhost:8000/2014/07/27/scraping-craigslist-for-tickets/" rel="alternate"></link><published>2014-07-27T00:00:00-05:00</published><author><name>Alex Fitts</name></author><id>tag:localhost:8000,2014-07-27:2014/07/27/scraping-craigslist-for-tickets/</id><summary type="html">&lt;p&gt;Recently, I've been listening to a lot of lo-fi rock band, &lt;a href="http://en.wikipedia.org/wiki/Cloud_Nothings"&gt;Cloud Nothings&lt;/a&gt;. Their album, &lt;a href="http://www.amazon.com/gp/product/B00HZJH97Q/ref=as_li_tl?ie=UTF8&amp;amp;camp=1789&amp;amp;creative=390957&amp;amp;creativeASIN=B00HZJH97Q&amp;amp;linkCode=as2&amp;amp;tag=gjreda-20&amp;amp;linkId=H7HYP35ZYKFAKH7H"&gt;Here &amp;amp; Nowhere Else&lt;/a&gt;, has been &lt;a href="http://www.metacritic.com/music/here-and-nowhere-else/cloud-nothings"&gt;critically lauded&lt;/a&gt;, including &lt;a href="http://pitchfork.com/reviews/albums/19075-cloud-nothings-here-and-nowhere-else/"&gt;garnering "Best New Music" from Pitchfork&lt;/a&gt;. As a result, when they came to Chicago's tiny Lincoln Hall in May, tickets sold out in a hurry - well before I found out about the show. Desperately wanting to go, I started checking Craigslist every day or two for tickets.&lt;/p&gt;
&lt;p&gt;Lincoln Hall only holds about 500 people, so Craigslist postings were few and far between. When a post did pop up, I always ended up seeing it a couple hours after it was posted and was too late - the tickets had been sold. Noticing that my frustration was beginning to grow, I figured it was time to automate my Craigslist searches for tickets.&lt;/p&gt;
&lt;p&gt;If you search on Craigslist and look at the URL of the results page, you'll notice that it looks very similar to this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Craigslist Search Results URL" src="/images/craigslist-search-results-url.png" /&gt;&lt;/p&gt;
&lt;p&gt;Note the section that says &lt;code&gt;query=this+is+my+search+term&lt;/code&gt; - that's where your search term gets passed to the databases that back Craigslist (with spaces replaced by + signs). This means we can write code to automate any "for sale" search by hitting &lt;code&gt;http://&amp;lt;city&amp;gt;.craigslist.org/search/sss?query=&amp;lt;term&amp;gt;&lt;/code&gt; where &lt;code&gt;&amp;lt;city&amp;gt;&lt;/code&gt; corresponds to the subdomain of your city's respective Craigslist and &lt;code&gt;&amp;lt;term&amp;gt;&lt;/code&gt; is our search term.&lt;/p&gt;
&lt;p&gt;For my use case, there were very few Craigslist results for each search of "Cloud Nothings" and none of them were spammy. I decided to write a script which would run every 10 minutes and send me a text message if any of the results were new. If I got a text, I could quickly head over to Craigslist, email the seller, and go back about my day. I was lucky that ticket brokers hadn't started putting "Cloud Nothings" in their spammy posts - if they had, this solution likely would not have worked - the text messages would have been more noise than signal.&lt;/p&gt;
&lt;p&gt;Thankfully, it worked. I was able to get a ticket for face value two nights before the show.&lt;/p&gt;
&lt;p&gt;In the sections below, I'll walk through the code behind it all. If you're unfamiliar with web scraping, I suggest reading my previous posts &lt;a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/"&gt;here&lt;/a&gt; and &lt;a href="http://www.gregreda.com/2013/05/06/more-web-scraping-with-python/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Code Walk-Through&lt;/h3&gt;
&lt;p&gt;Most of the code's functionality is contained within the four functions below.&lt;/p&gt;
&lt;h4&gt;parse_results&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_results&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search_term&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
    &lt;span class="n"&gt;search_term&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;search_term&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39; &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;+&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;search_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BASE_URL&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search_term&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;search_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;div&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;content&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;p&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;row&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;http://chicago.craigslist.org&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;create_date&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;span&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_text&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;a&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get_text&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;({&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;url&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;create_date&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;create_date&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above function takes a &lt;code&gt;search_term&lt;/code&gt;, which is used to execute a search on Craigslist. It returns a list of dictionaries, where each dictionary represents a post found within the search results.&lt;/p&gt;
&lt;p&gt;Note the global &lt;code&gt;BASE_URL&lt;/code&gt; variable - this is the search results URL mentioned earlier. Here, we're injecting our search term into the section of the URL that had &lt;code&gt;query=&amp;lt;term&amp;gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The majority of this function utilizes &lt;a href="http://www.crummy.com/software/BeautifulSoup/"&gt;BeautifulSoup&lt;/a&gt; to parse the HTML of Craigslist's search results page. For each post in the search results, we store the URL of the post, its creation date, and its title.&lt;/p&gt;
&lt;p&gt;In the next function, we'll write these results to a CSV file, which we'll later use to check whether or not there are "new" posts.&lt;/p&gt;
&lt;h4&gt;write_results&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;write_results&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="sd"&gt;&amp;quot;&amp;quot;&amp;quot;Writes list of dictionaries to file.&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;fields&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;results.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;dw&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictWriter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fieldnames&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fields&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;|&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;dw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writerow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;dw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fieldnames&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;dw&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writerows&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As mentioned above, &lt;code&gt;write_results&lt;/code&gt; takes a list of dictionaries and writes them to a CSV file called &lt;code&gt;results.csv&lt;/code&gt;. Each line of the file will store a post's title, create date, and URL.&lt;/p&gt;
&lt;p&gt;You can think of this file similarly to how you might think of a database - we're storing information that we'll need to refer to later on. Since we aren't storing much data, there's really no need to use something like SQLite, MySQL or any other datastore - a text file works just fine for our use case. I'm a big proponent of &lt;a href="http://en.wikipedia.org/wiki/KISS_principle"&gt;KISS methodology&lt;/a&gt; (Keep It Simple, Stupid).&lt;/p&gt;
&lt;h4&gt;has_new_records&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;has_new_records&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;current_posts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;x&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;url&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;x&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;fields&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;exists&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;results.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;

    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;results.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;r&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;reader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictReader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fieldnames&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fields&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;|&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;seen_posts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;row&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;url&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;row&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

    &lt;span class="n"&gt;is_new&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;False&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;current_posts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;post&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;seen_posts&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;pass&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;is_new&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="bp"&gt;True&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;is_new&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This function determines whether or not any of the posts are new (not present in the results from the last time our code was run).&lt;/p&gt;
&lt;p&gt;It takes a list of dictionaries (exactly the same as the one &lt;code&gt;parse_results&lt;/code&gt; returns) and checks it against the CSV file we created with the &lt;code&gt;write_results&lt;/code&gt; function. Since a URL can only point to one post, we can consider it a &lt;a href="http://en.wikipedia.org/wiki/Unique_key"&gt;unique key&lt;/a&gt; to check against.&lt;/p&gt;
&lt;p&gt;If any of the URLs in results are not found within the CSV file, this function will return &lt;code&gt;True&lt;/code&gt;, which we'll use as a trigger to sending off a text message as notification.&lt;/p&gt;
&lt;h4&gt;send_text&lt;/h4&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;send_text&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;phone_number&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;fromaddr&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Craigslist Checker&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;toaddrs&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;phone_number&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;@txt.att.net&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;msg&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;From: {0}&lt;/span&gt;&lt;span class="se"&gt;\r\n&lt;/span&gt;&lt;span class="s2"&gt;To: {1}&lt;/span&gt;&lt;span class="se"&gt;\r\n\r\n&lt;/span&gt;&lt;span class="s2"&gt;{2}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fromaddr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;toaddrs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;server&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;smtplib&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;SMTP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;smtp.gmail.com:587&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;server&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;starttls&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;server&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;login&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;email&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;username&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;email&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;password&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;server&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;sendmail&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fromaddr&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;toaddrs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;msg&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;server&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;quit&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;send_text&lt;/code&gt; requires two parameters - the first being the 10-digit phone number that will receive the SMS message, and the second being the content of the message.&lt;/p&gt;
&lt;p&gt;This function makes use of the &lt;a href="http://en.wikipedia.org/wiki/Simple_Mail_Transfer_Protocol"&gt;Simple Mail Transfer Protocol&lt;/a&gt; (or SMTP) as well as AT&amp;amp;T's email-to-SMS gateway (notice the &lt;code&gt;@txt.att.net&lt;/code&gt;). This allows us to use a GMail account to send the text message.&lt;/p&gt;
&lt;p&gt;Note that if you are not a GMail user or do not use AT&amp;amp;T for your cell phone service, you'll need to make some changes to this function. You can find a list of other email-to-SMS gateways &lt;a href="http://www.emailtextmessages.com/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Since this function uses my GMail credentials, I've stored them in a separate Python file which I am referencing when I call &lt;code&gt;config.email['username']&lt;/code&gt; and &lt;code&gt;config.email['password']&lt;/code&gt;. You can find the config setup &lt;a href="https://github.com/gjreda/craigslist-checker/blob/master/config.py"&gt;here&lt;/a&gt;. Just make sure you don't accidentally check in your GMail credentials if you're putting this on GitHub.&lt;/p&gt;
&lt;h4&gt;Putting it all together&lt;/h4&gt;
&lt;p&gt;You can take a look at the final script &lt;a href="https://github.com/gjreda/craigslist-checker/blob/master/craigslist.py"&gt;here&lt;/a&gt;. Feel free to use it however you'd like. Deploying it is as simple as spinning up a micro EC2 instance and setting up a cronjob to run the script as often as you'd like.&lt;/p&gt;
&lt;p&gt;Did you like this post? Was there something I missed? &lt;a href="https://twitter.com/gjreda"&gt;Let me know on Twitter&lt;/a&gt;.&lt;/p&gt;</summary><category term="scraping"></category><category term="tutorial"></category><category term="python"></category><category term="data"></category></entry><entry><title>Useful Unix commands for data science</title><link href="http://localhost:8000/2013/07/15/unix-commands-for-data-science/" rel="alternate"></link><published>2013-07-15T00:00:00-05:00</published><author><name>Alex Fitts</name></author><id>tag:localhost:8000,2013-07-15:2013/07/15/unix-commands-for-data-science/</id><summary type="html">&lt;p&gt;Imagine you have a 4.2GB CSV file.  It has over 12 million records and 50 columns.  All you need from this file is the sum of all values in one particular column.&lt;/p&gt;
&lt;p&gt;How would you do it?&lt;/p&gt;
&lt;p&gt;Writing a script in &lt;a href="http://www.python.org/"&gt;python&lt;/a&gt;/&lt;a href="http://www.ruby-lang.org/"&gt;ruby&lt;/a&gt;/&lt;a href="http://www.perl.org/"&gt;perl&lt;/a&gt;/whatever would probably take a few minutes and then even more time for the script to actually complete.  A &lt;a href="http://en.wikipedia.org/wiki/Database"&gt;database&lt;/a&gt; and &lt;a href="http://en.wikipedia.org/wiki/SQL"&gt;SQL&lt;/a&gt; would be fairly quick, but then you'd have load the data, which is kind of a pain.&lt;/p&gt;
&lt;p&gt;Thankfully, the &lt;a href="http://en.wikipedia.org/wiki/List_of_Unix_utilities"&gt;Unix utilities&lt;/a&gt; exist and they're awesome.&lt;/p&gt;
&lt;p&gt;To get the sum of a column in a huge text file, we can easily use &lt;a href="http://en.wikipedia.org/wiki/AWK_(programming_language)"&gt;awk&lt;/a&gt;.  And we won't even need to read the entire file into memory.&lt;/p&gt;
&lt;p&gt;Let's assume our data, which we'll call &lt;em&gt;data.csv&lt;/em&gt;, is pipe-delimited ( | ), and we want to sum the fourth column of the file.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;cat&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;awk&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;F&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;|&amp;quot;&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{ sum += $4 } END { printf &amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%.2f&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s1"&gt;&amp;quot;, sum }&amp;#39;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above line says:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use the &lt;a href="http://en.wikipedia.org/wiki/Cat_(Unix)"&gt;cat&lt;/a&gt; command to stream (print) the contents of the file to &lt;a href="http://en.wikipedia.org/wiki/Standard_streams"&gt;stdout&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://en.wikipedia.org/wiki/Pipeline_(Unix)"&gt;Pipe&lt;/a&gt; the streaming contents from our cat command to the next one - awk. &lt;/li&gt;
&lt;li&gt;
&lt;p&gt;With &lt;a href="http://en.wikipedia.org/wiki/AWK_(programming_language)"&gt;awk&lt;/a&gt;:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Set the field separator to the pipe character (-F "|"). Note that this has nothing to do with our pipeline in point #2.&lt;/li&gt;
&lt;li&gt;Increment the variable &lt;em&gt;sum&lt;/em&gt; with the value in the fourth column ($4). Since we used a pipeline in point #2, the contents of each line are being streamed to this statement.&lt;/li&gt;
&lt;li&gt;Once the stream is done, print out the value of &lt;em&gt;sum&lt;/em&gt;, using &lt;a href="http://www.gnu.org/software/gawk/manual/html_node/Printf-Examples.html"&gt;printf&lt;/a&gt; to format the value with two decimal places.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;It took less than two minutes to run on the entire file - much faster than other options and written in a lot fewer characters.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.hilarymason.com"&gt;Hilary Mason&lt;/a&gt; and &lt;a href="http://www.columbia.edu/~chw2/"&gt;Chris Wiggins&lt;/a&gt; wrote over at the &lt;a href="http://www.dataists.com/"&gt;dataists blog&lt;/a&gt; about the importance of any &lt;a href="http://www.dataists.com/2010/09/a-taxonomy-of-data-science/"&gt;data scientist being familiar with the command line&lt;/a&gt;, and I couldn't agree with them more.  The command line is essential to my daily work, so I wanted to share some of the commands I've found most useful.&lt;/p&gt;
&lt;p&gt;For those who are a bit newer to the command line than the rest of this post assumes, Hilary previously wrote a &lt;a href="http://www.hilarymason.com/articles/intro-to-the-linux-command-line/"&gt;nice introduction to it&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Other commands&lt;/h3&gt;
&lt;h4&gt;&lt;a href="http://en.wikipedia.org/wiki/Head_(Unix)"&gt;head&lt;/a&gt; &amp;amp; &lt;a href="http://en.wikipedia.org/wiki/Tail_(Unix)"&gt;tail&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;Sometimes you just need to inspect the structure of a huge file.  That's where &lt;a href="http://en.wikipedia.org/wiki/Head_(Unix)"&gt;head&lt;/a&gt; and &lt;a href="http://en.wikipedia.org/wiki/Tail_(Unix)"&gt;tail&lt;/a&gt; come in.  Head prints the first ten lines of a file, while tail prints the last ten lines.  Optionally, you can include the &lt;em&gt;-N&lt;/em&gt; parameter to change the number of lines displayed.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;
&lt;span class="c1"&gt;# time|away|score|home&lt;/span&gt;
&lt;span class="c1"&gt;# 20:00||0-0|Jump Ball won by Virginia Commonwealt.&lt;/span&gt;
&lt;span class="c1"&gt;# 19:45||0-0|Juvonte Reddic Turnover.&lt;/span&gt;

&lt;span class="n"&gt;tail&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;
&lt;span class="c1"&gt;# 0:14|Trey Davis Turnover.|62-71|&lt;/span&gt;
&lt;span class="c1"&gt;# 0:14||62-71|Briante Weber Steal.&lt;/span&gt;
&lt;span class="c1"&gt;# 0:00|End Game|End Game|End Game&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;&lt;a href="http://en.wikipedia.org/wiki/Wc_(Unix)"&gt;wc&lt;/a&gt; (word count)&lt;/h4&gt;
&lt;p&gt;By default, &lt;a href="http://en.wikipedia.org/wiki/Wc_(Unix)"&gt;wc&lt;/a&gt; will quickly tell you how many lines, words, and bytes are in a file.  If you're looking for just the line count, you can pass the &lt;em&gt;-l&lt;/em&gt; parameter in.&lt;/p&gt;
&lt;p&gt;I use it most often to verify record counts between files or database tables throughout an analysis.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;wc&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;
&lt;span class="c1"&gt;#     377    1697   17129 data.csv&lt;/span&gt;
&lt;span class="n"&gt;wc&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;
&lt;span class="c1"&gt;#     377 data.csv&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;&lt;a href="http://en.wikipedia.org/wiki/Grep"&gt;grep&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Grep"&gt;Grep&lt;/a&gt; allows you to search through plain text files using &lt;a href="http://en.wikipedia.org/wiki/Regular_expression"&gt;regular expressions&lt;/a&gt;.  I tend &lt;a href="http://regex.info/blog/2006-09-15/247"&gt;avoid regular expressions&lt;/a&gt; when possible, but still find grep to be invaluable when searching through log files for a particular event.&lt;/p&gt;
&lt;p&gt;There's an assortment of extra parameters you can use with grep, but the ones I tend to use the most are &lt;em&gt;-i&lt;/em&gt; (ignore case), &lt;em&gt;-r&lt;/em&gt; (recursively search directories), &lt;em&gt;-B N&lt;/em&gt; (N lines before), &lt;em&gt;-A N&lt;/em&gt; (N lines after).&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;grep&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;B&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;A&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="n"&gt;steal&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;
&lt;span class="c1"&gt;# 17:25||2-4|Darius Theus Turnover.&lt;/span&gt;
&lt;span class="c1"&gt;# 17:25|Terrell Vinson Steal.|2-4|&lt;/span&gt;
&lt;span class="c1"&gt;# 17:18|Chaz Williams made Layup.  Assisted by Terrell Vinson.|4-4|&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;&lt;a href="http://en.wikipedia.org/wiki/Sed"&gt;sed&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Sed"&gt;Sed&lt;/a&gt; is similar to &lt;a href="http://en.wikipedia.org/wiki/Grep"&gt;grep&lt;/a&gt; and &lt;a href="http://en.wikipedia.org/wiki/AWK_(programming_language)"&gt;awk&lt;/a&gt; in many ways, however I find that I most often use it when needing to do some find and replace magic on a very large file.  The usual occurrence is when I've received a CSV file that was generated on Windows and my &lt;a href="http://stackoverflow.com/questions/6373888/converting-newline-formatting-from-mac-to-windows"&gt;Mac isn't able to handle the carriage return&lt;/a&gt; properly.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;grep&lt;/span&gt; &lt;span class="n"&gt;Block&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="c1"&gt;# 16:43||5-4|Juvonte Reddic Block.&lt;/span&gt;
&lt;span class="c1"&gt;# 15:37||7-6|Troy Daniels Block.&lt;/span&gt;
&lt;span class="c1"&gt;# 14:05|Raphiael Putney Block.|11-8|&lt;/span&gt;

&lt;span class="n"&gt;sed&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;e&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;s/Block/Rejection/g&amp;#39;&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;rejection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;
&lt;span class="c1"&gt;# replace all instances of the word &amp;#39;Block&amp;#39; in data.csv with &amp;#39;Rejection&amp;#39;&lt;/span&gt;
&lt;span class="c1"&gt;# stream the results to a new file called rejection.csv&lt;/span&gt;

&lt;span class="n"&gt;grep&lt;/span&gt; &lt;span class="n"&gt;Rejection&lt;/span&gt; &lt;span class="n"&gt;rejection&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;3&lt;/span&gt;
&lt;span class="c1"&gt;# 16:43||5-4|Juvonte Reddic Rejection.&lt;/span&gt;
&lt;span class="c1"&gt;# 15:37||7-6|Troy Daniels Rejection.&lt;/span&gt;
&lt;span class="c1"&gt;# 14:05|Raphiael Putney Rejection.|11-8|&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;&lt;a href="http://en.wikipedia.org/wiki/Sort_(Unix)"&gt;sort&lt;/a&gt; &amp;amp; &lt;a href="http://en.wikipedia.org/wiki/Uniq"&gt;uniq&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Sort_(Unix)"&gt;Sort&lt;/a&gt; outputs the lines of a file in order based on a column key using the &lt;em&gt;-k&lt;/em&gt; parameter.  If a key isn't specified, sort will treat each line as a concatenated string and sort based on the values of the first column.  The &lt;em&gt;-n&lt;/em&gt; and &lt;em&gt;-r&lt;/em&gt; parameters allow you to sort numerically and in reverse order, respectively.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt;
&lt;span class="c1"&gt;# time|away|score|home&lt;/span&gt;
&lt;span class="c1"&gt;# 20:00||0-0|Jump Ball won by Virginia Commonwealt.&lt;/span&gt;
&lt;span class="c1"&gt;# 19:45||0-0|Juvonte Reddic Turnover.&lt;/span&gt;
&lt;span class="c1"&gt;# 19:45|Chaz Williams Steal.|0-0|&lt;/span&gt;
&lt;span class="c1"&gt;# 19:39|Sampson Carter missed Layup.|0-0|&lt;/span&gt;

&lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;sort&lt;/span&gt;
&lt;span class="c1"&gt;# 19:39|Sampson Carter missed Layup.|0-0|&lt;/span&gt;
&lt;span class="c1"&gt;# 19:45|Chaz Williams Steal.|0-0|&lt;/span&gt;
&lt;span class="c1"&gt;# 19:45||0-0|Juvonte Reddic Turnover.&lt;/span&gt;
&lt;span class="c1"&gt;# 20:00||0-0|Jump Ball won by Virginia Commonwealt.&lt;/span&gt;
&lt;span class="c1"&gt;# time|away|score|home&lt;/span&gt;

&lt;span class="c1"&gt;# columns separated by &amp;#39;|&amp;#39;, sort on column 2 (-k2), case insensitive (-f)&lt;/span&gt;
&lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;sort&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;|&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;k2&lt;/span&gt;
&lt;span class="c1"&gt;# time|away|score|home&lt;/span&gt;
&lt;span class="c1"&gt;# 19:45|Chaz Williams Steal.|0-0|&lt;/span&gt;
&lt;span class="c1"&gt;# 19:39|Sampson Carter missed Layup.|0-0|&lt;/span&gt;
&lt;span class="c1"&gt;# 20:00||0-0|Jump Ball won by Virginia Commonwealt.&lt;/span&gt;
&lt;span class="c1"&gt;# 19:45||0-0|Juvonte Reddic Turnover.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Sometimes you want to check for duplicate records in a large text file - that's when &lt;a href="http://en.wikipedia.org/wiki/Uniq"&gt;uniq&lt;/a&gt; comes in handy.  By using the &lt;em&gt;-c&lt;/em&gt; parameter, uniq will output the count of occurrences along with the line.  You can also use the &lt;em&gt;-d&lt;/em&gt; and &lt;em&gt;-u&lt;/em&gt; parameters to output only duplicated or unique records.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;sort&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;uniq&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;sort&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;nr&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;head&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;n&lt;/span&gt; &lt;span class="mi"&gt;7&lt;/span&gt;
&lt;span class="c1"&gt;#   2 8:47|Maxie Esho missed Layup.|46-54|&lt;/span&gt;
&lt;span class="c1"&gt;#   2 8:47|Maxie Esho Offensive Rebound.|46-54|&lt;/span&gt;
&lt;span class="c1"&gt;#   2 7:38|Trey Davis missed Free Throw.|51-56|&lt;/span&gt;
&lt;span class="c1"&gt;#   2 12:12||16-11|Rob Brandenberg missed Free Throw.&lt;/span&gt;
&lt;span class="c1"&gt;#   1 time|away|score|home&lt;/span&gt;
&lt;span class="c1"&gt;#   1 9:51||20-11|Juvonte Reddic Steal.&lt;/span&gt;

&lt;span class="n"&gt;sort&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;uniq&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;d&lt;/span&gt;
&lt;span class="c1"&gt;# 12:12||16-11|Rob Brandenberg missed Free Throw.&lt;/span&gt;
&lt;span class="c1"&gt;# 7:38|Trey Davis missed Free Throw.|51-56|&lt;/span&gt;
&lt;span class="c1"&gt;# 8:47|Maxie Esho Offensive Rebound.|46-54|&lt;/span&gt;
&lt;span class="c1"&gt;# 8:47|Maxie Esho missed Layup.|46-54|&lt;/span&gt;

&lt;span class="n"&gt;sort&lt;/span&gt; &lt;span class="n"&gt;data&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;csv&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;uniq&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;u&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;wc&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;
&lt;span class="c1"&gt;#     369 (unique lines)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;While it's sometimes difficult to remember all of the parameters for the Unix commands, getting familiar with them has been beneficial to my productivity and allowed me to avoid many headaches when working with large text files.&lt;/p&gt;
&lt;p&gt;Hopefully you'll find them as useful as I have.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additional Resources:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.drbunsen.org/explorations-in-unix/"&gt;Explorations in Unix&lt;/a&gt; by &lt;a href="http://www.drbunsen.org/"&gt;Seth Brown&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.ceri.memphis.edu/computer/docs/unix/bshell.htm"&gt;An Introduction to the Unix Shell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.comsysto.com/2013/04/25/data-analysis-with-the-unix-shell/"&gt;Data Analysis with the Unix Shell&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://jeroenjanssens.com/2013/09/19/seven-command-line-tools-for-data-science.html"&gt;7 Command Line Tools for Data Science&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</summary><category term="unix"></category><category term="terminal"></category><category term="data"></category><category term="data science"></category></entry><entry><title>How random is JavaScript's Math.random()?</title><link href="http://localhost:8000/2013/06/30/testing-javascripts-random-function/" rel="alternate"></link><published>2013-06-30T00:00:00-05:00</published><author><name>Alex Fitts</name></author><id>tag:localhost:8000,2013-06-30:2013/06/30/testing-javascripts-random-function/</id><summary type="html">&lt;p&gt;A few weeks back, I was talking with my friend &lt;a href="http://mollybierman.tumblr.com"&gt;Molly&lt;/a&gt; about personal domains and realized that her nickname, Bierface, was available.  The exchange basically went like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Me: I should buy bierface.com and just put up a ridiculous picture of you.&lt;/p&gt;
&lt;p&gt;Molly: You would have to do a slideshow. Too many gems.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="http://www.bierface.com"&gt;So I did just that&lt;/a&gt;, switching randomly between 14 pictures every time the page is loaded.  The laughs from it have been well worth the $10 spent purchasing the domain.&lt;/p&gt;
&lt;p&gt;She started to question the randomness though.  Here's what the code that loads each image looks like:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt; &lt;span class="na"&gt;href&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;http://mollybierman.tumblr.com&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;img&lt;/span&gt; &lt;span class="na"&gt;id&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;bierface&amp;quot;&lt;/span&gt; &lt;span class="na"&gt;src&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;/&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;a&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt; &lt;span class="na"&gt;type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;text/javascript&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
  &lt;span class="kd"&gt;var&lt;/span&gt; &lt;span class="nx"&gt;n&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;Math&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;ceil&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;Math&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;random&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mi"&gt;14&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;
  &lt;span class="nb"&gt;document&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nx"&gt;getElementById&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;bierface&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nx"&gt;src&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;./pictures/&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="nx"&gt;n&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;.jpg&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;&amp;lt;/&lt;/span&gt;&lt;span class="nt"&gt;script&lt;/span&gt;&lt;span class="p"&gt;&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;All we're doing is creating an empty &lt;em&gt;&lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt;&lt;/em&gt; element, and then changing the src attribute of that element via JavaScript.  The first line of JavaScript uses a combination of &lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/ceil"&gt;Math.ceil()&lt;/a&gt; and &lt;a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/random"&gt;Math.random()&lt;/a&gt; to get a random integer between 1 and 14 (which are how the images are named).  The second line uses that integer to create a file path and tells our &lt;em&gt;&lt;code&gt;&amp;lt;img&amp;gt;&lt;/code&gt;&lt;/em&gt; element to use that path as the src for the image.&lt;/p&gt;
&lt;p&gt;Since the image is loaded by your web client, this seemed like a great opportunity to learn the very basics of grabbing client-side data - I could write some code to repeatedly get which image was loaded in order to determine how random &lt;em&gt;Math.random()&lt;/em&gt; truly is.&lt;/p&gt;
&lt;h4&gt;The Setup&lt;/h4&gt;
&lt;p&gt;We're going to be using &lt;a href="http://jeanphix.me/Ghost.py/"&gt;Ghost.py&lt;/a&gt; to simulate a &lt;a href="http://en.wikipedia.org/wiki/WebKit"&gt;WebKit&lt;/a&gt; client.  Ghost.py requires &lt;a href="http://en.wikipedia.org/wiki/PyQt"&gt;PyQt&lt;/a&gt; or &lt;a href="http://en.wikipedia.org/wiki/PySide"&gt;PySide&lt;/a&gt;, so you'll want to grab one of those, too.  I'm on OSX 1.8.2 and using PySide 1.1.0 for Python 2.7, which you can get &lt;a href="http://qt-project.org/wiki/PySide_Binaries_MacOSX"&gt;here&lt;/a&gt;.  You'll also need to grab Qt 4.7, which you can find &lt;a href="http://packages.kitware.com/item/3736"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;The Code&lt;/h4&gt;
&lt;p&gt;With a little Python and Ghost.py, we can simulate a browser, allowing us to execute JavaScript telling us which image was loaded.  We can also use &lt;a href="http://matplotlib.org/"&gt;matplotlib&lt;/a&gt; to plot the distribution.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;ghost&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;Ghost&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class="kn"&gt;as&lt;/span&gt; &lt;span class="nn"&gt;plt&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;os&lt;/span&gt;

&lt;span class="n"&gt;ghost&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;Ghost&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;# JavaScript to grab the src file name for the image loaded&lt;/span&gt;
&lt;span class="n"&gt;js&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;document.getElementById(&amp;#39;bierface&amp;#39;).src.substr(33);&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# initialize zero&amp;#39;d out dictionary to hold image counts&lt;/span&gt;
&lt;span class="c1"&gt;# this way we can draw a nice, empty, base plot before we have actual values&lt;/span&gt;
&lt;span class="n"&gt;counts&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;dict&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;zip&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)]))&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;xrange&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;1002&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# draw empty plot on first pass&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;page_resources&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ghost&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;http://www.bierface.com&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ghost&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;evaluate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;js&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;image&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;int&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;.&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt; &lt;span class="c1"&gt;# grab just the image number&lt;/span&gt;
        &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;image&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;bar&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;values&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="n"&gt;align&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;center&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xticks&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;15&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="n"&gt;counts&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;keys&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xlabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;Image&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ylabel&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;# of times shown&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;title&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;n = {0}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zfill&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
    &lt;span class="n"&gt;plt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;grid&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;{0}/images/{1}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;getcwd&lt;/span&gt;&lt;span class="p"&gt;(),&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zfill&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="n"&gt;save&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;True&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;system&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;ffmpeg -f image2 -r 10 -i images/&lt;/span&gt;&lt;span class="si"&gt;%04d&lt;/span&gt;&lt;span class="s1"&gt;.png -s 480x360 random.avi&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let's walk though the code:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Load our libraries and create an instance of the Ghost class.&lt;/li&gt;
&lt;li&gt;Store the JavaScript we'll need to execute in order to grab the image file name into a variable named &lt;em&gt;js&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;The comment should explain this one - we're initializing a zero'd out dictionary called &lt;em&gt;counts&lt;/em&gt; so that our first plot doesn't have an x-axis with just one value.  Each key of the dictionary will correspond to one of the images.&lt;/li&gt;
&lt;li&gt;The &lt;a href="http://docs.python.org/2/reference/compound_stmts.html#for"&gt;for loop&lt;/a&gt; is used to run 1,000 simulations.  My &lt;a href="http://docs.python.org/2/library/functions.html#xrange"&gt;xrange&lt;/a&gt; usage is a little wacky because I'm using it to title and name the plots - typically &lt;em&gt;xrange&lt;/em&gt; starts with 0 and runs up &lt;em&gt;until&lt;/em&gt; the number specified (e.g. 1,001 will be the last loop, not 1,002).&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;This is the section that grabs which image was loaded by simulating a WebKit client with Ghost.py.  This section does not get run on the first pass since we want to start with an empty plot.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Load bierface.com into our &lt;em&gt;page&lt;/em&gt; variable.&lt;/li&gt;
&lt;li&gt;Execute the JavaScript mentioned in #2 and store it in the &lt;em&gt;image&lt;/em&gt; variable.  Remember that this will be a string.&lt;/li&gt;
&lt;li&gt;Split the &lt;em&gt;image&lt;/em&gt; string so that we just grab the image number loaded.&lt;/li&gt;
&lt;li&gt;Update our dictionary of counts for the given &lt;em&gt;image&lt;/em&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Here we're using &lt;a href="http://matplotlib.org/api/pyplot_api.html"&gt;matplotlib.pyplot&lt;/a&gt; to draw a bar chart.  Thanks to &lt;a href="http://www.jesshamrick.com/"&gt;Jess Hamrick&lt;/a&gt; for some awesome &lt;a href="http://www.jesshamrick.com/2012/09/03/saving-figures-from-pyplot/"&gt;plot-saving boilerplate&lt;/a&gt;, which I'm using behind the &lt;em&gt;save&lt;/em&gt; function.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;Finally, use &lt;a href="https://en.wikipedia.org/wiki/FFmpeg"&gt;ffmpeg&lt;/a&gt; to stitch our plots together into a video.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;The Results&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;Math.random()&lt;/em&gt; is pretty random (though #7 is the clear loser in the video below).  It's easy to think it's not when working with a small sample size, but it's clear the numbers start to even out as the sample size increases.&lt;/p&gt;
&lt;p&gt;&lt;center&gt;&lt;iframe width="480" height="360" src="//www.youtube.com/embed/y-tRXCyBk4w" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;&lt;/center&gt;&lt;/p&gt;</summary><category term="scraping"></category><category term="python"></category><category term="tutorial"></category><category term="data"></category></entry><entry><title>More web scraping with Python (and a map)</title><link href="http://localhost:8000/2013/04/29/more-web-scraping-with-python/" rel="alternate"></link><published>2013-04-29T00:00:00-05:00</published><author><name>Alex Fitts</name></author><id>tag:localhost:8000,2013-04-29:2013/04/29/more-web-scraping-with-python/</id><summary type="html">&lt;p&gt;&lt;em&gt;This is a follow-up to my &lt;a href="/2013/03/03/web-scraping-101-with-python/" title="Web Scraping 101 with Python"&gt;previous post&lt;/a&gt; about web scraping with Python&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Previously, I wrote a basic intro to scraping data off of websites.  Since I wanted to keep the intro fairly simple, I didn't cover storing the data.  In this post, I'll cover the basics of writing the scraped data to a flat file and then take things a bit further from there.&lt;/p&gt;
&lt;p&gt;Last time, we used the Chicago Reader's Best of 2011 list, but let's change it up a bit this time and scrape a different site.  Why?  Because scrapers break, so we might as well practice a little bit more by scraping something different.&lt;/p&gt;
&lt;p&gt;In this post, we're going to use the data from &lt;a href="http://www.chicagomag.com/Chicago-Magazine/November-2012/Best-Sandwiches-Chicago/"&gt;Chicago Magazine's Best Sandwiches list&lt;/a&gt; because ... who doesn't like sandwiches?&lt;/p&gt;
&lt;p&gt;If you're new to scraping, it might be a good idea to go back and read my &lt;a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/" title="Web Scraping 101 with Python"&gt;previous post&lt;/a&gt; as a refresher as I don't intend to be methodical in this one.&lt;/p&gt;
&lt;h4&gt;Finding the data&lt;/h4&gt;
&lt;p&gt;Looking at the list, it's clear everything is in a fairly standard format - each of the sandwiches in the list gets a &lt;em&gt;&lt;code&gt;&amp;lt;div class="sammy"&amp;gt;&lt;/code&gt;&lt;/em&gt; and each div holds a bit more information - specifically, the rank, sandwich name, location, and a URL to a detailed page about each entry.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Delicious sammy divs" src="/images/sammy-divs.png" /&gt;&lt;/p&gt;
&lt;p&gt;Clicking through a few of the sammy links, we can see that each sandwich also gets a detailed page that includes the sandwich's name, rank, description, and price along with the restaurant's name, address, phone number, and website.  Each of these details is contained within &lt;em&gt;&lt;code&gt;&amp;lt;div id="sandwich"&amp;gt;&lt;/code&gt;&lt;/em&gt;, which will make them very easy to get at.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Sandwich details HTML" src="/images/sammy-details.png" /&gt;&lt;/p&gt;
&lt;h4&gt;Package choices&lt;/h4&gt;
&lt;p&gt;We'll again be using the &lt;a href="http://www.crummy.com/software/BeautifulSoup/"&gt;BeautifulSoup&lt;/a&gt; and &lt;a href="http://docs.python.org/2/library/urllib2.html"&gt;urllib2&lt;/a&gt; libraries.  Last time around, the choice of these two libraries generated some discussion in the post's &lt;a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/#disqus_thread"&gt;comments section&lt;/a&gt;, on &lt;a href="http://www.reddit.com/r/Python/comments/19lnth/web_scraping_101_with_python_and_beautifulsoup/"&gt;Reddit&lt;/a&gt;, and &lt;a href="https://news.ycombinator.com/item?id=5353347"&gt;Hacker News&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The reason I use &lt;a href="http://www.crummy.com/software/BeautifulSoup/"&gt;BeautifulSoup&lt;/a&gt; is because I've found it to be very easy to use and understand, but YMMV.  It's been around for a very long time (since 2004) and is certainly in the tool belt of many.  That said, Python has a vast ecosystem with a lot of scraping libraries and ones like &lt;a href="http://scrapy.org/"&gt;Scrapy&lt;/a&gt; and &lt;a href="http://pythonhosted.org/pyquery/"&gt;PyQuery&lt;/a&gt; (amongst many others) are worth a look.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://docs.python.org/2/library/urllib2.html"&gt;Urllib2&lt;/a&gt; is &lt;em&gt;one&lt;/em&gt; of Python's URL handling packages within its standard library.  Because the standard library has &lt;a href="http://docs.python.org/2/library/urllib.html"&gt;urllib&lt;/a&gt; and &lt;a href="http://docs.python.org/2/library/urllib2.html"&gt;urllib2&lt;/a&gt;, it has at times been confusing to know which is the one you're actually looking for.  On top of that, &lt;a href="http://kennethreitz.org/"&gt;Kenneth Reitz&lt;/a&gt;'s fantastic &lt;a href="http://docs.python-requests.org/en/latest/"&gt;requests&lt;/a&gt; library exists, which really simplifies dealing with HTTP.&lt;/p&gt;
&lt;p&gt;In this example, and in the previous one, I use urllib2 simply because I &lt;em&gt;only&lt;/em&gt; need the &lt;a href="http://docs.python.org/2/library/urllib2.html#urllib2.urlopen"&gt;urlopen&lt;/a&gt; function.  If this scraper were more complex, I would likely use &lt;a href="http://docs.python-requests.org/en/latest/"&gt;requests&lt;/a&gt;, but I think using a third party library is a bit of overkill for this very simple use case.&lt;/p&gt;
&lt;h4&gt;Getting the data&lt;/h4&gt;
&lt;p&gt;Our code this time is going to be very similar to what it was &lt;a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/" title="Web Scraping 101 with Python"&gt;in the previous post&lt;/a&gt;, save for a few minor changes.  Since the details pages have the data we're looking for, let's get all of their URLs from the initial list page, and then process each details page.  We're also going to write all of the data to a tab-delimited file using Python's &lt;a href="http://docs.python.org/2/library/csv.html"&gt;CSV&lt;/a&gt; package.&lt;/p&gt;
&lt;p&gt;Last time around, we wrote our code as a set of functions, which I think helps the code's readability since it makes clear what each piece of the code is doing.  This time around, we're just going to write a short script since this is really a one-off thing - once we have our data written to a CSV, we don't really have a use for this code anymore.&lt;/p&gt;
&lt;p&gt;Our script will do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Load our libraries&lt;/li&gt;
&lt;li&gt;Read our &lt;em&gt;base_url&lt;/em&gt; into a BeautifulSoup object, grab all &lt;em&gt;&lt;code&gt;&amp;lt;div class="sammy"&amp;gt;&lt;/code&gt;&lt;/em&gt; sections, and then from each section, grab our sammy details URL.&lt;/li&gt;
&lt;li&gt;Open up a file named &lt;em&gt;src-best-sandwiches.tsv&lt;/em&gt; for writing.  We'll write to this file using Python's &lt;a href="http://docs.python.org/2/library/csv.html#csv.writer"&gt;csv.writer&lt;/a&gt; object and separate the fields by a tab (\t).  We'll also pass in a list of field names so that our file has a header row.&lt;/li&gt;
&lt;li&gt;Loop through all of our sammy details URLs, grabbing each piece of information we're interested in, and writing that data to our &lt;em&gt;src-best-sandwiches.tsv&lt;/em&gt; file.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;csv&lt;/span&gt;

&lt;span class="n"&gt;base_url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http://www.chicagomag.com/Chicago-Magazine/&amp;quot;&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;November-2012/Best-Sandwiches-Chicago/&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;base_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="n"&gt;sammies&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find_all&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;div&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;sammy&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;sammy_urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;div&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;href&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;div&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sammies&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;data/src-best-sandwiches.tsv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;fieldnames&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;rank&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;sandwich&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;restaurant&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                    &lt;span class="s2"&gt;&amp;quot;address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;phone&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;website&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writerow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;fieldnames&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sammy_urls&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http://www.chicagomag.com&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;  &lt;span class="c1"&gt;# inconsistent URL&lt;/span&gt;
        &lt;span class="n"&gt;page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http://www.chicagomag.com{0}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;div&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;sandwich&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;
        &lt;span class="n"&gt;rank&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;div&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;id&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;sandRank&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;})&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_contents&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;sandwich&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;h1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_contents&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&amp;lt;br/&amp;gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;restaurant&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;h1&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_contents&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;description&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_contents&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;addy&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;p&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;addy&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;em&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_contents&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;price&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;addy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;address&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;addy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;partition&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="n"&gt;phone&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;p&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;addy&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;em&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_contents&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;,&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;strip&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;p&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;addy&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;em&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;website&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;p&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;addy&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;em&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;encode_contents&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
        &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="n"&gt;website&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;

        &lt;span class="n"&gt;output&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writerow&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="n"&gt;rank&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;sandwich&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;restaurant&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;description&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;price&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        &lt;span class="n"&gt;address&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;phone&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;website&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Done writing file&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;While our scraper does a good job of getting all of the sandwiches and restaurants, a couple of restaurants had "multiple locations" listed as their address.  If we were to need this data, we'll have to find another way to get it (like checking each restaurant's website and manually adding their locations to our dataset).  We'll also need to manually fix some oddities that wound up in our data due some inconsistent HTML on the other end (addresses and URLs winding up in the phone numbers column).&lt;/p&gt;
&lt;p&gt;We're now left with a file full of data about Chicago Magazine's fifty best sandwiches.  Sure, it's nice to have the data structured neatly in a flat file, but that's not all that interesting.&lt;/p&gt;
&lt;p&gt;Collecting and hoarding data isn't of use to anyone - it's a waste of a potentially very valuable resource - it needs to be taken a step further.  In some cases, this means a thorough analysis in search of patterns and trends, surfacing relationships we did not necessarily expect, and utilizing that information to better our decision-making.  Data should be used to inform.  In some cases, even a very basic visualization of the data can be of use.&lt;/p&gt;
&lt;p&gt;Since we have addresses for each restaurant, this seems like a great time to make a map, but first, geocoding!&lt;/p&gt;
&lt;h4&gt;Geocoding&lt;/h4&gt;
&lt;p&gt;We're going to make our map using the &lt;a href="https://developers.google.com/maps/"&gt;Google Maps API&lt;/a&gt;, but in order to do so, we're first going to need to geocode our addresses to a set of lat/long points.  Don't worry, I've taken the time to manually fill in the blanks on those "multiple locations" restaurants (you can grab the new file from my &lt;a href="https://github.com/gjreda/best-sandwiches"&gt;GitHub repo&lt;/a&gt; - it's called &lt;em&gt;best-sandwiches.tsv&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;To do so, we'll just write a short Python script which hits the &lt;a href="https://developers.google.com/maps/documentation/geocoding/"&gt;Google Geocoding API&lt;/a&gt;.  Our script will do the following:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Read our &lt;em&gt;best-sandwiches.tsv&lt;/em&gt; file using the CSV module's &lt;a href="http://docs.python.org/2/library/csv.html#csv.DictReader"&gt;DictReader&lt;/a&gt; class, which reads each line of the file into its own dictionary object.&lt;/li&gt;
&lt;li&gt;For each address, make a call to the Google Geocoding API, which will return a JSON response full of details about that address.&lt;/li&gt;
&lt;li&gt;Using the &lt;a href="http://docs.python.org/2/library/csv.html#csv.DictWriter"&gt;DictWriter&lt;/a&gt; class, write a new file with our data along with the formatted address, lat, and long that we got back from the geocoder.&lt;/li&gt;
&lt;/ol&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;csv&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;time&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;sleep&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;geocode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;address&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;http://maps.googleapis.com/maps/api/geocode/json?&amp;quot;&lt;/span&gt;
        &lt;span class="s2"&gt;&amp;quot;sensor=false&amp;amp;address={0}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;address&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot; &amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;+&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;data/best-sandwiches.tsv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;r&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;reader&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictReader&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;f&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;with&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;data/best-sandwiches-geocode.tsv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;w&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;as&lt;/span&gt; &lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;fields&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;rank&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;sandwich&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;restaurant&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;description&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;price&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="s2"&gt;&amp;quot;address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;city&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;phone&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;website&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;full_address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                 &lt;span class="s2"&gt;&amp;quot;formatted_address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lat&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lng&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
        &lt;span class="n"&gt;writer&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;csv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DictWriter&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;fieldnames&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;fields&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;delimiter&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="se"&gt;\t&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writeheader&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;line&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;reader&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Geocoding: {0}&amp;quot;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;full_address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;response&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;geocode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;full_address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;status&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s2"&gt;u&amp;quot;OK&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;results&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;formatted_address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;formatted_address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;lat&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;geometry&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;location&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;lat&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;lng&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;geometry&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;location&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;lng&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
            &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;formatted_address&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;lat&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
                &lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;lng&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;&amp;quot;&lt;/span&gt;
            &lt;span class="n"&gt;sleep&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="n"&gt;writer&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;writerow&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;line&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;Done writing file&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Our file now has everything we need to make our map, which we're able to do with some basic HTML, CSS, JavaScript, and a little &lt;a href="https://developers.google.com/fusiontables/"&gt;Google Fusion Tables&lt;/a&gt; magic.&lt;/p&gt;
&lt;h4&gt;Mapping&lt;/h4&gt;
&lt;p&gt;While we could write another Python script to turn our flat file data into KML for mapping, it's much, much easier to use Google Fusion Tables.  However, one important note with the Fusion Tables approach is that the underlying data must be within a &lt;em&gt;public&lt;/em&gt; Fusion Table.  Since our data is scraped from a publicly accessible website, that's not an issue here.&lt;/p&gt;
&lt;p&gt;If you don't see Fusion Table as an option in your Google Drive account, you'll need to "connect more apps" and add it from there.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Adding Fusion Tables" src="/images/add-fusion-tables.png" /&gt;&lt;/p&gt;
&lt;p&gt;Once you've added the app, create a new Fusion Table from the delimited file on your computer (our &lt;em&gt;best-sandwiches-geocode.tsv&lt;/em&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img alt="Loading to Fusion Tables" src="/images/loading-to-fusion-tables.png" /&gt;&lt;/p&gt;
&lt;p&gt;After you've finished your upload process, you should now have a spreadsheet-like table with the data in it.  You'll notice that some of the columns are highlighted in yellow - this means that Fusion Tables is recognizing that it's a location.  Our lat and lng columns should be all the way at the right - hover over the lat column header and select &lt;em&gt;change&lt;/em&gt; from the drop down.  This should display a prompt showing us the column type is a two column location comprised of both our lat and lng.&lt;/p&gt;
&lt;p&gt;This is probably where I should point out that we could have also used Fusion Tables to geocode our data, but writing a script in Python seemed like more fun to me.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Lat Lng column type" src="/images/lat-lng-column-type.png" /&gt;&lt;/p&gt;
&lt;p&gt;Now that we have our data successfully in the Fusion Table, we can use a combination HTML, CSS, some JavaScript, and the Fusion Tables API to serve up a map (you could also just click the map tab in Fusion Tables to see an embedded map of the data, but that's not as fun).  We can even style the map with the &lt;a href="http://gmaps-samples-v3.googlecode.com/svn/trunk/styledmaps/wizard/index.html"&gt;Google Maps Style Wizard&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Head over to my &lt;a href="https://github.com/gjreda/best-sandwiches"&gt;GitHub repo&lt;/a&gt; to see the HTML, CSS, and JavaScript used to create the map (along with the rest of the code and data used throughout this post).  I've done my best to comment the &lt;em&gt;best-sandwiches.html&lt;/em&gt; file to indicate what each piece is doing.  I've also used HTML5's geolocation capabilities so that fellow Chicagoans can easily see which sandwiches are near them (it displays pretty nicely on a mobile browser, too).&lt;/p&gt;
&lt;p&gt;You can check out the awesome map we made &lt;a href="http://www.gregreda.com/best-sandwiches.html"&gt;here&lt;/a&gt;.  Note that if you aren't in Chicago and let your browser know your location, you likely won't see any of the data - you'll have to scroll over to Chicago.&lt;/p&gt;
&lt;p&gt;Hopefully you found this post fun and informative.  Was there something I didn't cover?  Let me know in the comments.&lt;/p&gt;</summary><category term="scraping"></category><category term="python"></category><category term="data"></category><category term="tutorial"></category><category term="maps"></category></entry><entry><title>Web Scraping 101 with Python</title><link href="http://localhost:8000/2013/03/03/web-scraping-101-with-python/" rel="alternate"></link><published>2013-03-03T00:00:00-06:00</published><author><name>Alex Fitts</name></author><id>tag:localhost:8000,2013-03-03:2013/03/03/web-scraping-101-with-python/</id><summary type="html">&lt;p&gt;&lt;em&gt;After you're done reading, check out my follow-up to this post &lt;a href="/2013/04/29/more-web-scraping-with-python/"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Yea, yea, I know I said I was going to &lt;a href="http://www.gregreda.com/2013/01/23/translating-sql-to-pandas-part1/"&gt;write more&lt;/a&gt; on &lt;a href="http://pandas.pydata.org"&gt;pandas&lt;/a&gt;, but recently I've had a couple friends ask me if I could teach them how to scrape data.  While they said they were able to find a ton of resources online, all assumed some level of knowledge already.  Here's my attempt at assuming a very minimal knowledge of programming.&lt;/p&gt;
&lt;h4&gt;Getting Setup&lt;/h4&gt;
&lt;p&gt;We're going to be using Python 2.7, &lt;a href="http://www.crummy.com/software/BeautifulSoup/"&gt;BeautifulSoup&lt;/a&gt;, and &lt;a href="http://lxml.de/"&gt;lxml&lt;/a&gt;.  If you don't already have Python 2.7, you'll want to download the proper version for your OS &lt;a href="http://python.org/download/releases/2.7.3/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To check if you have Python 2.7 on OSX, open up &lt;a href="http://en.wikipedia.org/wiki/Terminal_(OS_X)"&gt;Terminal&lt;/a&gt; and type &lt;em&gt;python --version&lt;/em&gt;.  You should see something like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="What Terminal should looks like" src="/images/python-version.png" /&gt;&lt;/p&gt;
&lt;p&gt;Next, you'll need to install &lt;a href="http://www.crummy.com/software/BeautifulSoup/"&gt;BeautifulSoup&lt;/a&gt;.  If you're on OSX, you'll already have &lt;a href="http://pypi.python.org/pypi/setuptools"&gt;setuptools&lt;/a&gt; installed.  Let's use it to install &lt;a href="http://www.pip-installer.org/en/latest/"&gt;pip&lt;/a&gt; and use that for package management instead.&lt;/p&gt;
&lt;p&gt;In Terminal, run &lt;em&gt;sudo easy_install pip&lt;/em&gt;.  You'll be prompted for your password - type it in and let it run.  Once that's done, again in Terminal, &lt;em&gt;sudo pip install BeautifulSoup4&lt;/em&gt;.  Finally, you'll need to &lt;a href="http://lxml.de/installation.html"&gt;install lxml&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;A few scraping rules&lt;/h4&gt;
&lt;p&gt;Now that we have the packages we need, we can start scraping.  But first, a couple of rules.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You should check a site's terms and conditions before you scrape them.  It's their data and they likely have some rules to govern it.&lt;/li&gt;
&lt;li&gt;Be nice - A computer will send web requests much quicker than a user can.  Make sure you space out your requests a bit so that you don't hammer the site's server.&lt;/li&gt;
&lt;li&gt;Scrapers break - Sites change their layout all the time.  If that happens, be prepared to rewrite your code.&lt;/li&gt;
&lt;li&gt;Web pages are inconsistent - There's sometimes some manual clean up that has to happen even after you've gotten your data.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Finding your data&lt;/h4&gt;
&lt;p&gt;For this example, we're going to use the &lt;a href="http://www.chicagoreader.com/chicago/best-of-chicago-2011/BestOf?oid=4100483"&gt;Chicago Reader's Best of 2011&lt;/a&gt; list.  Why?  Because I think it's a great example of terrible data presentation on the web.  Go ahead and browse it for a bit.&lt;/p&gt;
&lt;p&gt;All you want to see is a list of the category, winner, and maybe the runners-up, right?  But you have to continuously click link upon link, slowly navigating your way through the list.&lt;/p&gt;
&lt;p&gt;Hopefully in your clicking you noticed the important thing though - all the pages are structured the same.&lt;/p&gt;
&lt;h4&gt;Planning your code&lt;/h4&gt;
&lt;p&gt;In looking at the &lt;a href="http://www.chicagoreader.com/chicago/best-of-chicago-2011-food-drink/BestOf?oid=4106228"&gt;Food and Drink&lt;/a&gt; section of the Best of 2011 list, we see that all the categories are a link.  Each of those links has the winner, maybe some information about the winner (like an address), and the runners-up.  It's probably a good idea to break these things into separate functions in our code.&lt;/p&gt;
&lt;p&gt;To start, we need to take a look at the HTML that displays these categories.  If you're in Chrome or Firefox, highlight "Readers' Poll Winners", right-click, and select Inspect Element.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Inspect Element" src="/images/inspect-element.png" /&gt;&lt;/p&gt;
&lt;p&gt;This opens up the browser's Developer Tools (in Firefox, you might now have to click the HTML button on the right side of the developer pane to fully show it).  Now we'll be able to see the page layout.  The browser has brought us directly to the piece of HTML that's used to display the "Readers' Poll Winners" &lt;em&gt;&lt;code&gt;&amp;lt;dt&amp;gt;&lt;/code&gt;&lt;/em&gt; element.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Inspect Element some more" src="/images/inspect-element-more.png" /&gt;&lt;/p&gt;
&lt;p&gt;This seems to be the area of code where there's going to be some consistency in how the category links are displayed.  See that &lt;em&gt;&lt;code&gt;&amp;lt;dl class="boccat"&amp;gt;&lt;/code&gt;&lt;/em&gt; just above our "Readers' Poll Winners" line?  If you mouse over that line in your browser's dev tools, you'll notice that it highlights the &lt;strong&gt;entire section&lt;/strong&gt; of category links we want.  And every category link is within a &lt;em&gt;&lt;code&gt;&amp;lt;dd&amp;gt;&lt;/code&gt;&lt;/em&gt; element.  Perfect!  Let's get all of them.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Inspect Element mouse over" src="/images/inspect-element-mouseover.png" /&gt;&lt;/p&gt;
&lt;h4&gt;Our first function - getting the category links&lt;/h4&gt;
&lt;p&gt;Now that we know we know the &lt;em&gt;&lt;code&gt;&amp;lt;dl class="boccat"&amp;gt;&lt;/code&gt;&lt;/em&gt; section holds all the links we want, let's write some code to find that section, and then grab all of the links within the &lt;em&gt;&lt;code&gt;&amp;lt;dd&amp;gt;&lt;/code&gt;&lt;/em&gt; elements of that section.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;

&lt;span class="n"&gt;BASE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;http://www.chicagoreader.com&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_category_links&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;section_url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;section_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lxml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;boccat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;boccat&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;category_links&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;BASE_URL&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;dd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;href&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;dd&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;boccat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dd&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;category_links&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hopefully this code is relatively easy to follow, but if not, here's what we're doing:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Loading the urlopen function from the urllib2 library into our local &lt;a href="http://en.wikipedia.org/wiki/Namespace_(computer_science)"&gt;namespace&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Loading the BeautifulSoup class from the bs4 (BeautifulSoup4) library into our local namespace.&lt;/li&gt;
&lt;li&gt;Setting a variable named &lt;em&gt;BASE_URL&lt;/em&gt; to "http://www.chicagoreader.com".  We do this because the links used through the site are relative - meaning they do not include the base domain.  In order to store our links properly, we need to concatenate the base domain with each relative link.&lt;/li&gt;
&lt;li&gt;Define a function named &lt;em&gt;get_category_links&lt;/em&gt;.&lt;ol&gt;
&lt;li&gt;The function requires a parameter of &lt;em&gt;section_url&lt;/em&gt;.  In this example, we're going to use the &lt;a href="http://www.chicagoreader.com/chicago/best-of-chicago-2011-food-drink/BestOf?oid=4106228"&gt;Food and Drink&lt;/a&gt; section of the BOC list, however we could use a different section URL - for instance, the &lt;a href="http://www.chicagoreader.com/chicago/best-of-chicago-2011-city-life/BestOf?oid=4106233"&gt;City Life&lt;/a&gt; section's URL.  We're able to create just one generic function because each section page is structured the same.&lt;/li&gt;
&lt;li&gt;Open the section_url and read it in the &lt;em&gt;html&lt;/em&gt; object.&lt;/li&gt;
&lt;li&gt;Create an object called &lt;em&gt;soup&lt;/em&gt; based on the BeautifulSoup class.  The &lt;em&gt;soup&lt;/em&gt; object is an &lt;a href="http://en.wikipedia.org/wiki/Instance_(computer_science)"&gt;instance&lt;/a&gt; of the BeautifulSoup class.  It is initialized with the html object and parsed with &lt;a href="http://lxml.de/"&gt;lxml&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In our BeautifulSoup instance (which we called &lt;em&gt;soup&lt;/em&gt;), find the &lt;em&gt;&lt;code&gt;&amp;lt;dl&amp;gt;&lt;/code&gt;&lt;/em&gt; element with a class of "boccat" and store that section in a variable called &lt;em&gt;boccat&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;This is a &lt;a href="http://docs.python.org/2/tutorial/datastructures.html#list-comprehensions"&gt;list comprehension&lt;/a&gt;.  For every &lt;em&gt;&lt;code&gt;&amp;lt;dd&amp;gt;&lt;/code&gt;&lt;/em&gt; element found within our &lt;em&gt;boccat&lt;/em&gt; variable, we're getting the href of its &lt;em&gt;&lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt;&lt;/em&gt; element (our category links) and concatenating on our &lt;em&gt;BASE_URL&lt;/em&gt; to make it a complete link.  All of these links are being stored in a list called &lt;em&gt;category_links&lt;/em&gt;.  You could also write this line with a &lt;a href="http://docs.python.org/2/tutorial/controlflow.html#for-statements"&gt;for loop&lt;/a&gt;, but I prefer a list comprehension here because of its simplicity.&lt;/li&gt;
&lt;li&gt;Finally, our function returns the &lt;em&gt;category_links&lt;/em&gt; list that we created on the previous line.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Our second function - getting the category, winner, and runners-up&lt;/h4&gt;
&lt;p&gt;Now that we have our list of category links, we'd better start going through them to get our winners and runners-up.  Let's figure out which elements contain the parts we care about.&lt;/p&gt;
&lt;p&gt;If we look at the &lt;a href="http://www.chicagoreader.com/chicago/best-chef/BestOf?oid=4088191"&gt;Best Chef&lt;/a&gt; category, we can see that our category is in &lt;em&gt;&lt;code&gt;&amp;lt;h1 class="headline"&amp;gt;&lt;/code&gt;&lt;/em&gt;.  Shortly after that, we find our winner and runners-up stored in &lt;em&gt;&lt;code&gt;&amp;lt;h2 class="boc1"&amp;gt;&lt;/code&gt;&lt;/em&gt; and &lt;em&gt;&lt;code&gt;&amp;lt;h2 class="boc2"&amp;gt;&lt;/code&gt;&lt;/em&gt;, respectively.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Finding our winners and runners-up" src="/images/winners-and-runners-up.png" /&gt;&lt;/p&gt;
&lt;p&gt;Let's write some code to get all of them.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_category_winner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;category_url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;category_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lxml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;category&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;h1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;headline&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;
    &lt;span class="n"&gt;winner&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;h2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;h2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;h2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;boc1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;runners_up&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;h2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;h2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;h2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;boc2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;category&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;category&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;category_url&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;category_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;winner&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;winner&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;runners_up&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;runners_up&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's very similar to our last function, but let's walk through it anyway.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Define a function called &lt;em&gt;get_category_winner&lt;/em&gt;.  It requires a &lt;em&gt;category_url&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Lines two and three are actually exactly the same as before - we'll come back to this in the next section.&lt;/li&gt;
&lt;li&gt;Find the string within the &lt;em&gt;&lt;code&gt;&amp;lt;h1 class="headline"&amp;gt;&lt;/code&gt;&lt;/em&gt; element and store it in a variable named category.&lt;/li&gt;
&lt;li&gt;Another list comprehension - store the string within every &lt;em&gt;&lt;code&gt;&amp;lt;h2 class="boc1"&amp;gt;&lt;/code&gt;&lt;/em&gt; element in a list called &lt;em&gt;winner&lt;/em&gt;.  But shouldn't there be only one winner?  You'd think that, but some have multiple (e.g. &lt;a href="http://www.chicagoreader.com/chicago/best-bang-for-your-buck/BestOf?oid=4088018"&gt;Best Bang for your Buck&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Same as the previous line, but this time we're getting the runners-up.&lt;/li&gt;
&lt;li&gt;Finally, return a &lt;a href="http://docs.python.org/2/tutorial/datastructures.html#dictionaries"&gt;dictionary&lt;/a&gt; with our data.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;DRY - Don't Repeat Yourself&lt;/h4&gt;
&lt;p&gt;As mentioned in the previous section, lines two and three of our second function mirror lines in our first function.&lt;/p&gt;
&lt;p&gt;Imagine a scenario where we want to change the parser we're passing into our BeautifulSoup instance (in this case, lxml).  With the way we've currently written our code, we'd have to make that change in two places.  Now imagine you've written many more functions to scrape this data - maybe one to get addresses and another to get &lt;a href="http://www.chicagoreader.com/chicago/best-new-food-truckfood/BestOf?oid=4101387"&gt;paragraphs of text about the winner&lt;/a&gt; - you've likely repeated those same two lines of code in these functions and you now have to remember to make changes in four different places.  That's not ideal.&lt;/p&gt;
&lt;p&gt;A good principle in writing code is &lt;a href="http://en.wikipedia.org/wiki/Don't_repeat_yourself"&gt;DRY - Don't Repeat Yourself&lt;/a&gt;.  When you notice that you've written the same lines of code a couple times throughout your script, it's probably a good idea to step back and think if there's a better way to structure that piece.&lt;/p&gt;
&lt;p&gt;In our case, we're going to write another function to simply process a URL and return a BeautifulSoup instance.  We can then call this function in our other functions instead of duplicating our logic.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;make_soup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lxml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We'll have to change our other functions a bit now, but it's pretty minor - we just need to replace our duplicated lines with the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_soup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# where url is the url we&amp;#39;re passing into the original function&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Putting it all together&lt;/h4&gt;
&lt;p&gt;Now that we have our main functions written, we can write a script to output the data however we'd like.  Want to write to a CSV file?  Check out Python's &lt;a href="http://docs.python.org/2/library/csv.html#csv.DictWriter"&gt;DictWriter&lt;/a&gt; class.  Storing the data in a database?  Check out the &lt;a href="http://docs.python.org/2/library/sqlite3.html"&gt;sqlite3&lt;/a&gt; or &lt;a href="http://wiki.python.org/moin/DatabaseInterfaces"&gt;other various database libraries&lt;/a&gt;.  While both tasks are somewhat outside of my intentions for this post, if there's interest, let me know in the comments and I'd be happy to write more.&lt;/p&gt;
&lt;p&gt;Hopefully you found this post useful.  I've put a final example script in &lt;a href="http://bit.ly/13yd9ng"&gt;this gist&lt;/a&gt;.&lt;/p&gt;</summary><category term="scraping"></category><category term="python"></category><category term="data"></category><category term="tutorial"></category></entry></feed>