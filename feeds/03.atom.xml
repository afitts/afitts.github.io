<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Alex Fitts</title><link href="http://localhost:8000/" rel="alternate"></link><link href="http://localhost:8000/feeds/03.atom.xml" rel="self"></link><id>http://localhost:8000/</id><updated>2014-03-23T00:00:00-05:00</updated><entry><title>Principles of good data analysis</title><link href="http://localhost:8000/2014/03/23/principles-of-good-data-analysis/" rel="alternate"></link><published>2014-03-23T00:00:00-05:00</published><author><name>Alex Fitts</name></author><id>tag:localhost:8000,2014-03-23:2014/03/23/principles-of-good-data-analysis/</id><summary type="html">&lt;p&gt;Data analysis is hard.&lt;/p&gt;
&lt;p&gt;What makes it hard is the intuitive aspect of it - knowing the direction you want to take based on the limited information you have at the moment. Additionally, it's communicating the results and showing &lt;em&gt;why&lt;/em&gt; your analysis is right that makes this all the more difficult - doing it deeply, at scale, and in a &lt;em&gt;consistent&lt;/em&gt; fashion.&lt;/p&gt;
&lt;p&gt;Having been a part of many of these deep-dive analyses, I've noticed some "principles" that I've found useful to follow throughout.&lt;/p&gt;
&lt;h4&gt;Know your approach&lt;/h4&gt;
&lt;p&gt;Before you begin the analysis, know the questions you're trying to answer and what you're trying to accomplish - don't fall into an analytical rabbit hole. Additionally, you should know some basic things about your potential data - what data sources are available to answer the questions? How is that data structured? Is it in a database? CSVs? Third-party APIs? What tools will you be able to use for the analysis?&lt;/p&gt;
&lt;p&gt;Your approach will likely change throughout, but it's helpful to start with a plan and adjust.&lt;/p&gt;
&lt;h4&gt;Know how the data was generated&lt;/h4&gt;
&lt;p&gt;Once you've settled on your approach and data sources, you need to make sure you understand how the data was generated or captured, especially if you are using your own company's data.&lt;/p&gt;
&lt;p&gt;For instance, let's say you're a data scientist at Amazon and you're doing some analysis on orders. Let's assume there's a table somewhere in the Amazon world called "orders" that stores data about an order. Does this table store incomplete orders? What is the interaction on Amazon.com that creates a new record in this table? If I start an order and do not &lt;em&gt;fully&lt;/em&gt; complete the payment flow, will a record have been written to this table? What &lt;em&gt;exactly&lt;/em&gt; does each field in the table mean?&lt;/p&gt;
&lt;p&gt;You need to know this level of detail in order to have confidence in your analysis - your audience will ask these questions.&lt;/p&gt;
&lt;h4&gt;Profile your data&lt;/h4&gt;
&lt;p&gt;Once you're confident you're looking at the right data, you need to develop some familiarity it. Not only will this allow you to gain a basic understanding of what you're looking at, but it also allows you to gain a certain level of comfort that things are still "right" later on in the analysis.&lt;/p&gt;
&lt;p&gt;For example, I was once helping a friend analyze a fairly large time series dataset (~10GB). The results of the analysis didn't intuitively jive with me - something felt off. When digging deeper into the analysis, I decided to plot the events by date and noticed we had two days without any data - that shouldn't have been the case.&lt;/p&gt;
&lt;p&gt;Profiling your data early on helps to ensure your work throughout the analysis - you'll notice sooner when something is "off."&lt;/p&gt;
&lt;h4&gt;Facet all the things&lt;/h4&gt;
&lt;p&gt;I'm increasingly convinced that &lt;a href="http://en.wikipedia.org/wiki/Simpson's_paradox"&gt;Simpson's Paradox&lt;/a&gt; is one of the most important things for anyone working with data to understand. In cases of Simpson's paradox, a trend appearing in different groups of data disappears when the groups are combined and looked at in aggregate. It illustrates the importance of looking at your data by multiple dimensions.&lt;/p&gt;
&lt;p&gt;As an example, take a look at the below table.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Simpson's paradox (combined)" src="/images/simpsons-paradox-combined.png" /&gt;&lt;/p&gt;
&lt;p&gt;The above table shows admission rates for men and women into the University of California, Berkeley's graduate programs for the fall of 1973. Based on the above numbers, the University was sued for an alledged bias against women. However, when faceting the data by sex AND department, we see women were actually admitted into many departments' graduate programs at a rate higher than men.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Simpson's paradox (splits)" src="/images/simpsons-paradox-split.png" /&gt;&lt;/p&gt;
&lt;p&gt;This is probably the most infamous case of Simpson's paradox. The folks over at Berkeley's VUDLab have put together a &lt;a href="http://vudlab.com/simpsons/"&gt;fantastic visualization&lt;/a&gt; allowing you to explore the data further.&lt;/p&gt;
&lt;p&gt;When going through your data, do so with Simpson's paradox in mind. It's extremely important to understand how aggregate statistics can be misleading and why looking at your data from multiple facets is necessary.&lt;/p&gt;
&lt;h4&gt;Be skeptical&lt;/h4&gt;
&lt;p&gt;In addition to profiling and faceting your data, you &lt;em&gt;need&lt;/em&gt; to be skeptical throughout your analysis. If something doesn't look or feel right, it probably isn't. Pore through your data to make sure nothing unexpected going on, and if there &lt;em&gt;is&lt;/em&gt; something unexpected, make sure you understand why it's occurring and are comfortable with it before you proceed.&lt;/p&gt;
&lt;p&gt;I'd argue that no data is better than incorrect data in most cases. Make sure the base layer of your analysis is correct.&lt;/p&gt;
&lt;h4&gt;Think like a trial lawyer&lt;/h4&gt;
&lt;p&gt;A good trial attorney will prepare their case while also considering how the opposition might respond. When the opposition does present, our attorney will (hopefully) have prepared for that very piece of new evidence or testimony, easily allowing he/she to counter in a meaningful way.&lt;/p&gt;
&lt;p&gt;Much like a good trial attorney, you need to think ahead and consider the audience of your analysis and the questions they might ask. Preparing appropriately for those will lend to the credibility of your work. No one likes to hear "I'm not sure, I didn't look at that" and you don't want to be caught flat-footed.&lt;/p&gt;
&lt;h4&gt;Clarify your assumptions&lt;/h4&gt;
&lt;p&gt;It's unlikely that your data is perfect and it probably doesn't capture everything you need to complete a thorough and exhaustive analysis - you'll need to hold some assumptions throughout your work. These need to be explicitly stated when you're sharing results.&lt;/p&gt;
&lt;p&gt;Additionally, your stakeholders are crucial in helping you determine your assumptions. You should be working with them and other domain experts to ensure your assumptions are logical and unbiased.&lt;/p&gt;
&lt;h4&gt;Check your work&lt;/h4&gt;
&lt;p&gt;It seems obvious, but people just don't check their work sometimes. Understandably, there are deadlines, quick turnarounds, and last minute requests; however, I can assure you that your audience would rather your results be correct than quick.&lt;/p&gt;
&lt;p&gt;I find it useful to regularly check the basic statistics of the data (sums, counts, etc.) throughout an analysis in order to make sure nothing is lost along the way - essentially creating a trail of breadcrumbs I can follow backwards in case something doesn't seem right later on.&lt;/p&gt;
&lt;h4&gt;Communicate&lt;/h4&gt;
&lt;p&gt;Lastly, the whole process should be a conversation with stakeholders - don't work in a silo. It's possible your audience isn't necessarily concerned with decimal point accuracy - maybe they just want to understand directional impact.&lt;/p&gt;
&lt;p&gt;In the end, remember that data analysis is most often about &lt;em&gt;solving a problem&lt;/em&gt; and that problem has stakeholders - you should be working &lt;em&gt;with&lt;/em&gt; them to answer the questions that are most important; not necessarily those that are most interesting. Interesting doesn't always mean "valuable."&lt;/p&gt;</summary><category term="data science"></category><category term="frameworks"></category><category term="methodology"></category><category term="thoughts"></category></entry><entry><title>Write online about what you love</title><link href="http://localhost:8000/2013/03/16/why-you-should-write-online/" rel="alternate"></link><published>2013-03-16T00:00:00-05:00</published><author><name>Alex Fitts</name></author><id>tag:localhost:8000,2013-03-16:2013/03/16/why-you-should-write-online/</id><summary type="html">&lt;p&gt;The other week, I wrote a &lt;a href="http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/"&gt;very basic intro to web scraping with Python&lt;/a&gt;.  Some friends knew that I had experience scraping data and they wanted to learn, so I figured it would be a great opportunity to write something publicly and test how well I could explain it.&lt;/p&gt;
&lt;p&gt;I'll be extending that scraping post a bit more in the future, but first I wanted to write about how the week and a half since I posted it has gone - or, explain why I think you should write online about what you love.&lt;/p&gt;
&lt;h4&gt;How it started&lt;/h4&gt;
&lt;p&gt;Shortly after finishing the post and feeling fairly satisfied with the way it turned out, I posted it and e-mailed a link to three of my friends - two of which were the ones who asked me to teach them.  One of them, &lt;a href="https://twitter.com/kennylong"&gt;Kenny&lt;/a&gt;, immediately messaged me, read through the post, and said I should share it on Twitter.  &lt;a href="https://twitter.com/gjreda/status/308337050065727489"&gt;So I did&lt;/a&gt;.  To me, any feedback was better than no feedback, so I posted it &lt;a href="http://www.reddit.com/r/Python/comments/19lnth/web_scraping_101_with_python_and_beautifulsoup/"&gt;in the Python subreddit&lt;/a&gt; too.&lt;/p&gt;
&lt;p&gt;I was really just hoping some people would see it and let me know what they thought.&lt;/p&gt;
&lt;p&gt;Turns out, quite a few more people than my 92 followers (at the time) have seen it in the week and a half since.  About 32,000 more.&lt;/p&gt;
&lt;p&gt;It was pretty exhilarating to watch something I wrote be shared in real-time.  Many of the &lt;a href="https://twitter.com/siah/status/308719789524799488"&gt;data&lt;/a&gt; &lt;a href="https://twitter.com/treycausey/status/308342790180458496"&gt;nerds&lt;/a&gt; that I admire and follow on Twitter were sharing it.  Hell, even Philadelphia's Chief Data Officer &lt;a href="https://twitter.com/mheadd/status/308576308810637312"&gt;shared it&lt;/a&gt;.  It was a ton of fun to watch and read both (fairly) positive and constructive comments about it on /r/python.  It immediately made me want to write the post you're currently reading, which I started working on two days later.&lt;/p&gt;
&lt;h4&gt;A week later&lt;/h4&gt;
&lt;p&gt;Sitting around the following Sunday, making minor CSS tweaks to this site and finishing up the previously mentioned post, I decided to check my Google Analytics to see what the final traffic from /r/python and Twitter looked like.  Surprisingly, the real-time section of Analytics showed 250+ on the site.  What?  How?!&lt;/p&gt;
&lt;p&gt;That's when I realized it wound up at the top of &lt;a href="https://news.ycombinator.com/item?id=5353347"&gt;Hacker News&lt;/a&gt;.  And then &lt;a href="http://www.reddit.com/r/programming/comments/1a20lf/web_scraping_101_with_python/"&gt;/r/programming&lt;/a&gt;.  Traffic went through the roof.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Hacker News, /r/programming, and lots of Twitter sharing" src="/images/more-traffic-20130313.png" /&gt;&lt;/p&gt;
&lt;p&gt;And again, the comments were positive and constructive.&lt;/p&gt;
&lt;h4&gt;Lesson learned&lt;/h4&gt;
&lt;p&gt;And this leads me to why you should write about things you're passionate about online.  When you're truly passionate about something, you spend a lot of time thinking and learning about it - you try to make it a part of your life.  You try to become a reputable source on the topic (or even an expert).  It can be something as broad as beer, personal finance, or film; or as niche as stand-up comedy, vegan baking, or &lt;a href="http://en.wikipedia.org/wiki/Emo#Underground_popularity:_mid-1990s"&gt;90s midwest emo bands&lt;/a&gt; (guilty).  It doesn't matter what it is as long as &lt;em&gt;you&lt;/em&gt; love it.&lt;/p&gt;
&lt;p&gt;Like me, you're likely ecstatic when you find someone you're able to get nerdy with about something you love.  You truly enjoy the topic and are always looking for ways to &lt;em&gt;learn more&lt;/em&gt; and &lt;em&gt;teach others&lt;/em&gt; about it (or just banter).&lt;/p&gt;
&lt;p&gt;That's why you should share your knowledge about whatever the field may be.  &lt;em&gt;It doesn't matter whether 10 or 10,000 people see what you've shared&lt;/em&gt;.  There are people interested, but might not know where to start.  And that's the best way to reinforce how well we know something - by teaching it to others.  You'll be prompted with questions you hadn't thought about before, which will only further your own curiosity.  You're forced to explain concepts in simple terms that anyone can understand - you become a better teacher and communicator.  Sometimes, someone else crazily passionate about the same topic will even come along and teach you a thing or two.&lt;/p&gt;
&lt;p&gt;We all have a thirst for knowledge in some form.  The internet's a magnificent place to test our existing knowledge by teaching others and learning more throughout the process thanks to feedback from those with differing experiences.&lt;/p&gt;
&lt;p&gt;Put your passions out there.  More often than not, you'll be amazed at what you get back.&lt;/p&gt;</summary><category term="writing"></category><category term="thoughts"></category></entry><entry><title>Web Scraping 101 with Python</title><link href="http://localhost:8000/2013/03/03/web-scraping-101-with-python/" rel="alternate"></link><published>2013-03-03T00:00:00-06:00</published><author><name>Alex Fitts</name></author><id>tag:localhost:8000,2013-03-03:2013/03/03/web-scraping-101-with-python/</id><summary type="html">&lt;p&gt;&lt;em&gt;After you're done reading, check out my follow-up to this post &lt;a href="/2013/04/29/more-web-scraping-with-python/"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Yea, yea, I know I said I was going to &lt;a href="http://www.gregreda.com/2013/01/23/translating-sql-to-pandas-part1/"&gt;write more&lt;/a&gt; on &lt;a href="http://pandas.pydata.org"&gt;pandas&lt;/a&gt;, but recently I've had a couple friends ask me if I could teach them how to scrape data.  While they said they were able to find a ton of resources online, all assumed some level of knowledge already.  Here's my attempt at assuming a very minimal knowledge of programming.&lt;/p&gt;
&lt;h4&gt;Getting Setup&lt;/h4&gt;
&lt;p&gt;We're going to be using Python 2.7, &lt;a href="http://www.crummy.com/software/BeautifulSoup/"&gt;BeautifulSoup&lt;/a&gt;, and &lt;a href="http://lxml.de/"&gt;lxml&lt;/a&gt;.  If you don't already have Python 2.7, you'll want to download the proper version for your OS &lt;a href="http://python.org/download/releases/2.7.3/"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To check if you have Python 2.7 on OSX, open up &lt;a href="http://en.wikipedia.org/wiki/Terminal_(OS_X)"&gt;Terminal&lt;/a&gt; and type &lt;em&gt;python --version&lt;/em&gt;.  You should see something like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="What Terminal should looks like" src="/images/python-version.png" /&gt;&lt;/p&gt;
&lt;p&gt;Next, you'll need to install &lt;a href="http://www.crummy.com/software/BeautifulSoup/"&gt;BeautifulSoup&lt;/a&gt;.  If you're on OSX, you'll already have &lt;a href="http://pypi.python.org/pypi/setuptools"&gt;setuptools&lt;/a&gt; installed.  Let's use it to install &lt;a href="http://www.pip-installer.org/en/latest/"&gt;pip&lt;/a&gt; and use that for package management instead.&lt;/p&gt;
&lt;p&gt;In Terminal, run &lt;em&gt;sudo easy_install pip&lt;/em&gt;.  You'll be prompted for your password - type it in and let it run.  Once that's done, again in Terminal, &lt;em&gt;sudo pip install BeautifulSoup4&lt;/em&gt;.  Finally, you'll need to &lt;a href="http://lxml.de/installation.html"&gt;install lxml&lt;/a&gt;.&lt;/p&gt;
&lt;h4&gt;A few scraping rules&lt;/h4&gt;
&lt;p&gt;Now that we have the packages we need, we can start scraping.  But first, a couple of rules.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;You should check a site's terms and conditions before you scrape them.  It's their data and they likely have some rules to govern it.&lt;/li&gt;
&lt;li&gt;Be nice - A computer will send web requests much quicker than a user can.  Make sure you space out your requests a bit so that you don't hammer the site's server.&lt;/li&gt;
&lt;li&gt;Scrapers break - Sites change their layout all the time.  If that happens, be prepared to rewrite your code.&lt;/li&gt;
&lt;li&gt;Web pages are inconsistent - There's sometimes some manual clean up that has to happen even after you've gotten your data.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Finding your data&lt;/h4&gt;
&lt;p&gt;For this example, we're going to use the &lt;a href="http://www.chicagoreader.com/chicago/best-of-chicago-2011/BestOf?oid=4100483"&gt;Chicago Reader's Best of 2011&lt;/a&gt; list.  Why?  Because I think it's a great example of terrible data presentation on the web.  Go ahead and browse it for a bit.&lt;/p&gt;
&lt;p&gt;All you want to see is a list of the category, winner, and maybe the runners-up, right?  But you have to continuously click link upon link, slowly navigating your way through the list.&lt;/p&gt;
&lt;p&gt;Hopefully in your clicking you noticed the important thing though - all the pages are structured the same.&lt;/p&gt;
&lt;h4&gt;Planning your code&lt;/h4&gt;
&lt;p&gt;In looking at the &lt;a href="http://www.chicagoreader.com/chicago/best-of-chicago-2011-food-drink/BestOf?oid=4106228"&gt;Food and Drink&lt;/a&gt; section of the Best of 2011 list, we see that all the categories are a link.  Each of those links has the winner, maybe some information about the winner (like an address), and the runners-up.  It's probably a good idea to break these things into separate functions in our code.&lt;/p&gt;
&lt;p&gt;To start, we need to take a look at the HTML that displays these categories.  If you're in Chrome or Firefox, highlight "Readers' Poll Winners", right-click, and select Inspect Element.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Inspect Element" src="/images/inspect-element.png" /&gt;&lt;/p&gt;
&lt;p&gt;This opens up the browser's Developer Tools (in Firefox, you might now have to click the HTML button on the right side of the developer pane to fully show it).  Now we'll be able to see the page layout.  The browser has brought us directly to the piece of HTML that's used to display the "Readers' Poll Winners" &lt;em&gt;&lt;code&gt;&amp;lt;dt&amp;gt;&lt;/code&gt;&lt;/em&gt; element.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Inspect Element some more" src="/images/inspect-element-more.png" /&gt;&lt;/p&gt;
&lt;p&gt;This seems to be the area of code where there's going to be some consistency in how the category links are displayed.  See that &lt;em&gt;&lt;code&gt;&amp;lt;dl class="boccat"&amp;gt;&lt;/code&gt;&lt;/em&gt; just above our "Readers' Poll Winners" line?  If you mouse over that line in your browser's dev tools, you'll notice that it highlights the &lt;strong&gt;entire section&lt;/strong&gt; of category links we want.  And every category link is within a &lt;em&gt;&lt;code&gt;&amp;lt;dd&amp;gt;&lt;/code&gt;&lt;/em&gt; element.  Perfect!  Let's get all of them.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Inspect Element mouse over" src="/images/inspect-element-mouseover.png" /&gt;&lt;/p&gt;
&lt;h4&gt;Our first function - getting the category links&lt;/h4&gt;
&lt;p&gt;Now that we know we know the &lt;em&gt;&lt;code&gt;&amp;lt;dl class="boccat"&amp;gt;&lt;/code&gt;&lt;/em&gt; section holds all the links we want, let's write some code to find that section, and then grab all of the links within the &lt;em&gt;&lt;code&gt;&amp;lt;dd&amp;gt;&lt;/code&gt;&lt;/em&gt; elements of that section.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;bs4&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;urllib2&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;

&lt;span class="n"&gt;BASE_URL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;http://www.chicagoreader.com&amp;quot;&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_category_links&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;section_url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;section_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lxml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;boccat&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dl&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;boccat&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;category_links&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;BASE_URL&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;dd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;href&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;dd&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;boccat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;dd&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;category_links&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Hopefully this code is relatively easy to follow, but if not, here's what we're doing:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Loading the urlopen function from the urllib2 library into our local &lt;a href="http://en.wikipedia.org/wiki/Namespace_(computer_science)"&gt;namespace&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Loading the BeautifulSoup class from the bs4 (BeautifulSoup4) library into our local namespace.&lt;/li&gt;
&lt;li&gt;Setting a variable named &lt;em&gt;BASE_URL&lt;/em&gt; to "http://www.chicagoreader.com".  We do this because the links used through the site are relative - meaning they do not include the base domain.  In order to store our links properly, we need to concatenate the base domain with each relative link.&lt;/li&gt;
&lt;li&gt;Define a function named &lt;em&gt;get_category_links&lt;/em&gt;.&lt;ol&gt;
&lt;li&gt;The function requires a parameter of &lt;em&gt;section_url&lt;/em&gt;.  In this example, we're going to use the &lt;a href="http://www.chicagoreader.com/chicago/best-of-chicago-2011-food-drink/BestOf?oid=4106228"&gt;Food and Drink&lt;/a&gt; section of the BOC list, however we could use a different section URL - for instance, the &lt;a href="http://www.chicagoreader.com/chicago/best-of-chicago-2011-city-life/BestOf?oid=4106233"&gt;City Life&lt;/a&gt; section's URL.  We're able to create just one generic function because each section page is structured the same.&lt;/li&gt;
&lt;li&gt;Open the section_url and read it in the &lt;em&gt;html&lt;/em&gt; object.&lt;/li&gt;
&lt;li&gt;Create an object called &lt;em&gt;soup&lt;/em&gt; based on the BeautifulSoup class.  The &lt;em&gt;soup&lt;/em&gt; object is an &lt;a href="http://en.wikipedia.org/wiki/Instance_(computer_science)"&gt;instance&lt;/a&gt; of the BeautifulSoup class.  It is initialized with the html object and parsed with &lt;a href="http://lxml.de/"&gt;lxml&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In our BeautifulSoup instance (which we called &lt;em&gt;soup&lt;/em&gt;), find the &lt;em&gt;&lt;code&gt;&amp;lt;dl&amp;gt;&lt;/code&gt;&lt;/em&gt; element with a class of "boccat" and store that section in a variable called &lt;em&gt;boccat&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;This is a &lt;a href="http://docs.python.org/2/tutorial/datastructures.html#list-comprehensions"&gt;list comprehension&lt;/a&gt;.  For every &lt;em&gt;&lt;code&gt;&amp;lt;dd&amp;gt;&lt;/code&gt;&lt;/em&gt; element found within our &lt;em&gt;boccat&lt;/em&gt; variable, we're getting the href of its &lt;em&gt;&lt;code&gt;&amp;lt;a&amp;gt;&lt;/code&gt;&lt;/em&gt; element (our category links) and concatenating on our &lt;em&gt;BASE_URL&lt;/em&gt; to make it a complete link.  All of these links are being stored in a list called &lt;em&gt;category_links&lt;/em&gt;.  You could also write this line with a &lt;a href="http://docs.python.org/2/tutorial/controlflow.html#for-statements"&gt;for loop&lt;/a&gt;, but I prefer a list comprehension here because of its simplicity.&lt;/li&gt;
&lt;li&gt;Finally, our function returns the &lt;em&gt;category_links&lt;/em&gt; list that we created on the previous line.&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;Our second function - getting the category, winner, and runners-up&lt;/h4&gt;
&lt;p&gt;Now that we have our list of category links, we'd better start going through them to get our winners and runners-up.  Let's figure out which elements contain the parts we care about.&lt;/p&gt;
&lt;p&gt;If we look at the &lt;a href="http://www.chicagoreader.com/chicago/best-chef/BestOf?oid=4088191"&gt;Best Chef&lt;/a&gt; category, we can see that our category is in &lt;em&gt;&lt;code&gt;&amp;lt;h1 class="headline"&amp;gt;&lt;/code&gt;&lt;/em&gt;.  Shortly after that, we find our winner and runners-up stored in &lt;em&gt;&lt;code&gt;&amp;lt;h2 class="boc1"&amp;gt;&lt;/code&gt;&lt;/em&gt; and &lt;em&gt;&lt;code&gt;&amp;lt;h2 class="boc2"&amp;gt;&lt;/code&gt;&lt;/em&gt;, respectively.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Finding our winners and runners-up" src="/images/winners-and-runners-up.png" /&gt;&lt;/p&gt;
&lt;p&gt;Let's write some code to get all of them.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;get_category_winner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;category_url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;category_url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lxml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;category&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;h1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;headline&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt;
    &lt;span class="n"&gt;winner&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;h2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;h2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;h2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;boc1&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="n"&gt;runners_up&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;h2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;string&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;h2&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;soup&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;findAll&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;h2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;boc2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;category&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;category&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;category_url&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;category_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;winner&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;winner&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            &lt;span class="s2"&gt;&amp;quot;runners_up&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt; &lt;span class="n"&gt;runners_up&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It's very similar to our last function, but let's walk through it anyway.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Define a function called &lt;em&gt;get_category_winner&lt;/em&gt;.  It requires a &lt;em&gt;category_url&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;Lines two and three are actually exactly the same as before - we'll come back to this in the next section.&lt;/li&gt;
&lt;li&gt;Find the string within the &lt;em&gt;&lt;code&gt;&amp;lt;h1 class="headline"&amp;gt;&lt;/code&gt;&lt;/em&gt; element and store it in a variable named category.&lt;/li&gt;
&lt;li&gt;Another list comprehension - store the string within every &lt;em&gt;&lt;code&gt;&amp;lt;h2 class="boc1"&amp;gt;&lt;/code&gt;&lt;/em&gt; element in a list called &lt;em&gt;winner&lt;/em&gt;.  But shouldn't there be only one winner?  You'd think that, but some have multiple (e.g. &lt;a href="http://www.chicagoreader.com/chicago/best-bang-for-your-buck/BestOf?oid=4088018"&gt;Best Bang for your Buck&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;Same as the previous line, but this time we're getting the runners-up.&lt;/li&gt;
&lt;li&gt;Finally, return a &lt;a href="http://docs.python.org/2/tutorial/datastructures.html#dictionaries"&gt;dictionary&lt;/a&gt; with our data.&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;DRY - Don't Repeat Yourself&lt;/h4&gt;
&lt;p&gt;As mentioned in the previous section, lines two and three of our second function mirror lines in our first function.&lt;/p&gt;
&lt;p&gt;Imagine a scenario where we want to change the parser we're passing into our BeautifulSoup instance (in this case, lxml).  With the way we've currently written our code, we'd have to make that change in two places.  Now imagine you've written many more functions to scrape this data - maybe one to get addresses and another to get &lt;a href="http://www.chicagoreader.com/chicago/best-new-food-truckfood/BestOf?oid=4101387"&gt;paragraphs of text about the winner&lt;/a&gt; - you've likely repeated those same two lines of code in these functions and you now have to remember to make changes in four different places.  That's not ideal.&lt;/p&gt;
&lt;p&gt;A good principle in writing code is &lt;a href="http://en.wikipedia.org/wiki/Don't_repeat_yourself"&gt;DRY - Don't Repeat Yourself&lt;/a&gt;.  When you notice that you've written the same lines of code a couple times throughout your script, it's probably a good idea to step back and think if there's a better way to structure that piece.&lt;/p&gt;
&lt;p&gt;In our case, we're going to write another function to simply process a URL and return a BeautifulSoup instance.  We can then call this function in our other functions instead of duplicating our logic.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;make_soup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;html&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;urlopen&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;BeautifulSoup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;html&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;lxml&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;We'll have to change our other functions a bit now, but it's pretty minor - we just need to replace our duplicated lines with the following:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="n"&gt;soup&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;make_soup&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# where url is the url we&amp;#39;re passing into the original function&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;Putting it all together&lt;/h4&gt;
&lt;p&gt;Now that we have our main functions written, we can write a script to output the data however we'd like.  Want to write to a CSV file?  Check out Python's &lt;a href="http://docs.python.org/2/library/csv.html#csv.DictWriter"&gt;DictWriter&lt;/a&gt; class.  Storing the data in a database?  Check out the &lt;a href="http://docs.python.org/2/library/sqlite3.html"&gt;sqlite3&lt;/a&gt; or &lt;a href="http://wiki.python.org/moin/DatabaseInterfaces"&gt;other various database libraries&lt;/a&gt;.  While both tasks are somewhat outside of my intentions for this post, if there's interest, let me know in the comments and I'd be happy to write more.&lt;/p&gt;
&lt;p&gt;Hopefully you found this post useful.  I've put a final example script in &lt;a href="http://bit.ly/13yd9ng"&gt;this gist&lt;/a&gt;.&lt;/p&gt;</summary><category term="scraping"></category><category term="python"></category><category term="data"></category><category term="tutorial"></category></entry></feed>